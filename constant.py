# -*- coding: utf-8 -*-
"""DIP_Lab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NxukCjO-mUasaV8dFutra8R_sya7e5t2

Implement the image negative transformation function and apply it to a grayscale image.
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

def apply_negative_transformation(image):
    """
    Apply the image negative transformation to a grayscale image.

    Parameters:
        image (numpy.ndarray): Input grayscale image.

    Returns:
        numpy.ndarray: Image after applying negative transformation.
    """
    if len(image.shape) != 2:
        raise ValueError("Input image must be grayscale.")

    # Perform negative transformation: new_pixel = 255 - old_pixel
    negative_image = 255 - image

    return negative_image

def main():
    # Load the grayscale image
    image_path = '/content/56368408-58561980-61c5-11e9-9800-0678dc02b4e7.png'  # Replace with your image path
    grayscale_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    if grayscale_image is None:
        raise FileNotFoundError("Image file not found. Check the path.")

    # Apply the negative transformation
    negative_image = apply_negative_transformation(grayscale_image)

    # Display the original and negative images
    plt.figure(figsize=(10, 5))

    plt.subplot(1, 2, 1)
    plt.title("Original Image")
    plt.imshow(grayscale_image, cmap='gray')
    plt.axis('off')

    plt.subplot(1, 2, 2)
    plt.title("Negative Image")
    plt.imshow(negative_image, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

"""Analyze the effect of image negative on different types of images (e.g., low contrast, high
contrast).
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Function to compute image negative
def image_negative(image):
    return 255 - image

# Function to display images side by side
def display_images(original, transformed, title1="Original", title2="Transformed"):
    plt.figure(figsize=(10, 5))

    # Original image
    plt.subplot(1, 2, 1)
    plt.imshow(original, cmap='gray')
    plt.title(title1)
    plt.axis('off')

    # Transformed image
    plt.subplot(1, 2, 2)
    plt.imshow(transformed, cmap='gray')
    plt.title(title2)
    plt.axis('off')

    plt.tight_layout()
    plt.show()

# Load sample images

low_contrast_image = cv2.imread('/content/p3292964492-5-533x800.jpg', cv2.IMREAD_GRAYSCALE)
high_contrast_image = cv2.imread('/content/1000304.jpg', cv2.IMREAD_GRAYSCALE)

if low_contrast_image is None or high_contrast_image is None:
    print("Please ensure the image files are available in the specified paths.")
else:
    # Apply image negative transformation
    low_contrast_negative = image_negative(low_contrast_image)
    high_contrast_negative = image_negative(high_contrast_image)

    # Display results
    print("Low Contrast Image Analysis")
    display_images(low_contrast_image, low_contrast_negative, "Low Contrast", "Negative")

    print("High Contrast Image Analysis")
    display_images(high_contrast_image, high_contrast_negative, "High Contrast", "Negative")

"""Compare the histogram of an original image with its negative. Explain the observed
differences.
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load a grayscale image
image = cv2.imread('/content/56368408-58561980-61c5-11e9-9800-0678dc02b4e7.png', cv2.IMREAD_GRAYSCALE)

# Create the negative of the image
negative_image = 255 - image

# Calculate histograms for the original and negative images
original_hist = cv2.calcHist([image], [0], None, [256], [0, 256])
negative_hist = cv2.calcHist([negative_image], [0], None, [256], [0, 256])

# Normalize histograms for better comparison
original_hist /= original_hist.sum()
negative_hist /= negative_hist.sum()

# Plot the histograms
plt.figure(figsize=(12, 6))

# Original Image Histogram
plt.subplot(1, 2, 1)
plt.title("Original Image Histogram")
plt.xlabel("Pixel Intensity")
plt.ylabel("Frequency")
plt.plot(original_hist, color='blue')
plt.grid()

# Negative Image Histogram
plt.subplot(1, 2, 2)
plt.title("Negative Image Histogram")
plt.xlabel("Pixel Intensity")
plt.ylabel("Frequency")
plt.plot(negative_hist, color='red')
plt.grid()

# Show the plots
plt.tight_layout()
plt.show()

"""Implement the log transformation function and apply it to an image with a narrow range of
low gray-level values.
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

def log_transform(image):
    """
    Apply log transformation to an image.

    Parameters:
        image (numpy.ndarray): Input image.

    Returns:
        numpy.ndarray: Log-transformed image.
    """
    # Convert the image to float32 for precision in log transformation
    image_float = image.astype(np.float32)

    # Apply log transformation
    c = 255 / (np.log(1 + np.max(image_float)))  # Scaling constant
    log_image = c * np.log(1 + image_float)

    # Convert back to uint8
    log_image = np.uint8(log_image)

    return log_image

# Load an image with a narrow range of low gray-level values
# You can replace 'low_gray_image.jpg' with the path to your image
image_path = "/content/mage-Suffering-from-Un-even-illumination-Grey-Level-Image-size-512x512.png"
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

if image is None:
    raise FileNotFoundError(f"Image not found at {image_path}")

# Apply the log transformation
log_image = log_transform(image)

# Display the original and log-transformed images
plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plt.title("Original Image")
plt.imshow(image, cmap='gray')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.title("Log-Transformed Image")
plt.imshow(log_image, cmap='gray')
plt.axis('off')

plt.tight_layout()
plt.show()

# Save the log-transformed image (optional)
cv2.imwrite("log_transformed_image.jpg", log_image)

import cv2
import numpy as np
import matplotlib.pyplot as plt

def log_transform(image):
    """
    Apply log transformation to an image.

    Parameters:
        image (numpy.ndarray): Input image.

    Returns:
        numpy.ndarray: Log-transformed image.
    """
    # Convert the image to float32 for precision in log transformation
    image_float = image.astype(np.float32)

    # Apply log transformation
    c = 255 / (np.log(1 + np.max(image_float)))  # Scaling constant
    log_image = c * np.log(1 + image_float)

    # Convert back to uint8
    log_image = np.uint8(log_image)

    return log_image

# Load an image with a narrow range of low gray-level values
# You can replace 'low_gray_image.jpg' with the path to your image
image_path = "/content/einstein.jpg"
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

if image is None:
    raise FileNotFoundError(f"Image not found at {image_path}")

# Apply the log transformation
log_image = log_transform(image)

# Display the original and log-transformed images
plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plt.title("Original Image")
plt.imshow(image, cmap='gray')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.title("Log-Transformed Image")
plt.imshow(log_image, cmap='gray')
plt.axis('off')

plt.tight_layout()
plt.show()

# Save the log-transformed image (optional)
cv2.imwrite("log_transformed_image.jpg", log_image)

"""Analyze the effect of the log transformation on enhancing details in dark regions of an image."""

import cv2
import numpy as np
import matplotlib.pyplot as plt

def log_transform(image):
    """
    Apply log transformation to an image.

    Parameters:
        image (numpy.ndarray): Input image.

    Returns:
        numpy.ndarray: Log-transformed image.
    """
    # Convert the image to float32 for precision in log transformation
    image_float = image.astype(np.float32)

    # Apply log transformation
    c = 255 / (np.log(1 + np.max(image_float)))  # Scaling constant
    log_image = c * np.log(1 + image_float)

    # Convert back to uint8
    log_image = np.uint8(log_image)

    return log_image

# Analyze the effect of the log transformation

def analyze_log_transformation(original_image, transformed_image):
    """
    Analyze the effect of log transformation on enhancing details in dark regions.

    Parameters:
        original_image (numpy.ndarray): Original input image.
        transformed_image (numpy.ndarray): Log-transformed image.
    """
    # Compute histograms
    original_hist = cv2.calcHist([original_image], [0], None, [256], [0, 256])
    transformed_hist = cv2.calcHist([transformed_image], [0], None, [256], [0, 256])

    # Plot histograms and images
    plt.figure(figsize=(12, 8))

    # Original image and its histogram
    plt.subplot(2, 2, 1)
    plt.title("Original Image")
    plt.imshow(original_image, cmap='gray')
    plt.axis('off')

    plt.subplot(2, 2, 2)
    plt.title("Histogram of Original Image")
    plt.plot(original_hist, color='blue')
    plt.xlim([0, 256])

    # Log-transformed image and its histogram
    plt.subplot(2, 2, 3)
    plt.title("Log-Transformed Image")
    plt.imshow(transformed_image, cmap='gray')
    plt.axis('off')

    plt.subplot(2, 2, 4)
    plt.title("Histogram of Log-Transformed Image")
    plt.plot(transformed_hist, color='green')
    plt.xlim([0, 256])

    plt.tight_layout()
    plt.show()

# Load an image with a narrow range of low gray-level values
# You can replace 'low_gray_image.jpg' with the path to your image
image_path = "/content/einstein.jpg"
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

if image is None:
    raise FileNotFoundError(f"Image not found at {image_path}")

# Apply the log transformation
log_image = log_transform(image)

# Display the original and log-transformed images
plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plt.title("Original Image")
plt.imshow(image, cmap='gray')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.title("Log-Transformed Image")
plt.imshow(log_image, cmap='gray')
plt.axis('off')

plt.tight_layout()
plt.show()

# Analyze the effect
analyze_log_transformation(image, log_image)

# Save the log-transformed image (optional)
cv2.imwrite("log_transformed_image.jpg", log_image)

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load the image
image = cv2.imread('/content/images (7).jpeg', cv2.IMREAD_GRAYSCALE)

# Apply log transformation
c = 255 / np.log(1 + np.max(image))  # Scaling constant
log_transformed = c * np.log(1 + image.astype(np.float32))

# Normalize the log-transformed image
log_transformed = np.uint8(cv2.normalize(log_transformed, None, 0, 255, cv2.NORM_MINMAX))

# Plot the original and transformed images
plt.figure(figsize=(10, 5))

plt.subplot(1, 2, 1)
plt.title("Original Image")
plt.imshow(image, cmap='gray')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.title("Log Transformed Image")
plt.imshow(log_transformed, cmap='gray')
plt.axis('off')

plt.tight_layout()
plt.show()

"""Experiment with different values of the constant 'c' in the log transformation equation and
observe the changes in output image.
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

def log_transformation(image, c):
    """
    Apply log transformation to an image.

    Parameters:
        image (numpy.ndarray): Input grayscale image.
        c (float): Constant for log transformation.

    Returns:
        numpy.ndarray: Log-transformed image.
    """
    # Ensure the input image is in float format for log transformation
    image = image.astype(np.float32)

    # Apply the log transformation equation
    log_image = c * np.log1p(image)

    # Normalize to the range [0, 255] for visualization
    log_image = cv2.normalize(log_image, None, 0, 255, cv2.NORM_MINMAX)
    log_image = np.uint8(log_image)

    return log_image

def display_images(images, titles, rows, cols):
    """
    Display multiple images in a grid.

    Parameters:
        images (list of numpy.ndarray): List of images to display.
        titles (list of str): List of titles for the images.
        rows (int): Number of rows in the grid.
        cols (int): Number of columns in the grid.
    """
    plt.figure(figsize=(15, 10))
    for i, (image, title) in enumerate(zip(images, titles)):
        plt.subplot(rows, cols, i + 1)
        plt.imshow(image, cmap='gray')
        plt.title(title)
        plt.axis('off')
    plt.tight_layout()
    plt.show()

# Load the input image
image_path = "/content/56368408-58561980-61c5-11e9-9800-0678dc02b4e7.png"  # Replace with your image path
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

if image is None:
    raise ValueError("Image not found at the specified path.")

# Define different values of c to experiment with
c_values = [1, 5, 10, 20]

# Apply log transformation for each value of c and store the results
images = [image]
titles = ["Original Image"]

for c in c_values:
    transformed_image = log_transformation(image, c)
    images.append(transformed_image)
    titles.append(f"Log Transform (c = {c})")

# Display the images
display_images(images, titles, rows=1, cols=len(images))

"""Implement the power-law transformation function with different values of gamma."""

import numpy as np
import matplotlib.pyplot as plt

def power_law_transformation(image, gamma):
    """
    Apply power-law (gamma) transformation to an image.

    Parameters:
        image (ndarray): Input image (can be grayscale or color).
        gamma (float): Gamma value for the transformation.

    Returns:
        transformed_image (ndarray): Gamma-transformed image.
    """
    # Normalize the image to the range [0, 1]
    image_normalized = image / 255.0

    # Apply the power-law transformation
    transformed_image = np.power(image_normalized, gamma)

    # Rescale to [0, 255] and convert back to uint8
    transformed_image = np.uint8(transformed_image * 255)

    return transformed_image

# Example usage
if __name__ == "__main__":
    # Load an example image (you can replace this with your image path)

    image = plt.imread('/content/einstein.jpg')

    # Test with different gamma values
    gamma_values = [0.5, 1.0, 2.0]

    plt.figure(figsize=(12, 4))

    for i, gamma in enumerate(gamma_values):
        transformed_image = power_law_transformation(image, gamma)
        plt.subplot(1, len(gamma_values), i+1)
        plt.imshow(transformed_image)
        plt.title(f'Gamma = {gamma}')
        plt.axis('off')

    plt.show()

"""Apply the power-law transformation to enhance images with different contrast characteristics."""

import cv2
import numpy as np
import matplotlib.pyplot as plt

def power_law_transformation(image, gamma):
    # Normalize the image to the range [0, 1]
    normalized_image = image / 255.0

    # Apply the power-law transformation
    transformed_image = np.power(normalized_image, gamma)

    # Convert back to the range [0, 255]
    transformed_image = np.uint8(transformed_image * 255)

    return transformed_image

# Read an image
image_path = '/content/einstein.jpg'  # Replace with your image path
image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load the image in grayscale

# Apply the power-law transformation with a gamma value
gamma = 2.0  # You can adjust this value
transformed_image = power_law_transformation(image, gamma)

# Display the original and transformed images side by side
plt.figure(figsize=(10, 5))

# Original Image
plt.subplot(1, 2, 1)
plt.imshow(image, cmap='gray')
plt.title('Original Image')
plt.axis('off')

# Transformed Image
plt.subplot(1, 2, 2)
plt.imshow(transformed_image, cmap='gray')
plt.title(f'Power-Law Transformed Image (Gamma={gamma})')
plt.axis('off')

plt.show()

"""Analyze the effect of gamma values on the image appearance, especially for values less than
and greater than 1
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Function to apply gamma correction
def gamma_correction(image, gamma):
    # Normalize the image to range [0, 1]
    image_normalized = image / 255.0
    # Apply gamma correction
    image_corrected = np.power(image_normalized, gamma)
    # Rescale back to [0, 255]
    image_corrected = np.uint8(image_corrected * 255)
    return image_corrected

# Read the image
image = cv2.imread('/content/einstein.jpg')

# Convert BGR to RGB for displaying with Matplotlib
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Different gamma values to test
gamma_values = [0.5, 1, 1.5, 2.0]

# Plot the original image and images with different gamma values
plt.figure(figsize=(12, 8))

# Original image
plt.subplot(2, 3, 1)
plt.imshow(image_rgb)
plt.title('Original Image')
plt.axis('off')

# Gamma corrected images
for i, gamma in enumerate(gamma_values):
    corrected_image = gamma_correction(image_rgb, gamma)
    plt.subplot(2, 3, i + 2)
    plt.imshow(corrected_image)
    plt.title(f'Gamma = {gamma}')
    plt.axis('off')

plt.tight_layout()
plt.show()

"""Experiment with different image types (e.g., medical, satellite, natural) to observe the impact
of transformations
"""

import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt

# Function to apply power-law transformation
def powerlaw_transformation(image, gamma=1.0):
    # Normalize image to the range [0, 1]
    image = np.array(image, dtype=np.float32) / 255.0
    # Apply the power-law transformation
    transformed_image = np.power(image, gamma)
    # Convert back to range [0, 255] and uint8
    transformed_image = np.uint8(transformed_image * 255)
    return transformed_image

# Load sample images of different types
# Replace these paths with actual paths to your images
image_paths = [
    "/content/MRI_blackandwhite.png",   # e.g., X-ray or MRI image
    "/content/Greyscale-satellite-image-centred-on-SIRTAs-Laboratory-48713-N-2208-E_Q320.jpg",  # e.g., satellite imagery
    "/content/einstein.jpg"    # e.g., landscape or nature image
]

# Set gamma values to experiment with
gamma_values = [0.5, 1.0, 2.0]

# Plot original and transformed images for each type
fig, axes = plt.subplots(len(image_paths), len(gamma_values) + 1, figsize=(12, 6))
for i, image_path in enumerate(image_paths):
    # Load image using OpenCV or PIL
    image = Image.open(image_path)

    # Show original image
    axes[i][0].imshow(image)
    axes[i][0].set_title("Original")
    axes[i][0].axis('off')

    # Apply and display power-law transformations for each gamma value
    for j, gamma in enumerate(gamma_values):
        transformed_image = powerlaw_transformation(image, gamma)
        axes[i][j + 1].imshow(transformed_image, cmap='gray')
        axes[i][j + 1].set_title(f"Gamma = {gamma}")
        axes[i][j + 1].axis('off')

plt.tight_layout()
plt.show()

"""Spatial Filtering
1. Implement mean, median, and Gaussian filters. Apply them to images with different noise
types (salt-and-pepper, Gaussian) and compare the results.
2. Design a custom filter for sharpening edges while preserving image details. Apply it to a
natural image and evaluate its performance.
3. Experiment with different Laplacian operators (4-connected, 8-connected) and compare their
edge detection capabilities.
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Read the image
image = cv2.imread('/content/einstein.jpg', cv2.IMREAD_GRAYSCALE)

# Adding salt-and-pepper noise to the image
def add_salt_pepper_noise(image, salt_prob, pepper_prob):
    noisy_image = image.copy()
    total_pixels = image.size
    num_salt = int(total_pixels * salt_prob)
    num_pepper = int(total_pixels * pepper_prob)

    # Add salt (white) noise
    salt_coords = [np.random.randint(0, i-1, num_salt) for i in image.shape]
    noisy_image[salt_coords[0], salt_coords[1]] = 255

    # Add pepper (black) noise
    pepper_coords = [np.random.randint(0, i-1, num_pepper) for i in image.shape]
    noisy_image[pepper_coords[0], pepper_coords[1]] = 0

    return noisy_image

# Gaussian noise function
def add_gaussian_noise(image, mean=0, var=0.01):
    row, col = image.shape
    sigma = var**0.5
    gauss = np.random.normal(mean, sigma, (row, col))
    noisy = np.uint8(np.clip(image + gauss, 0, 255))
    return noisy

# Apply filters
mean_filtered = cv2.blur(image, (5, 5))
median_filtered = cv2.medianBlur(image, 5)
gaussian_filtered = cv2.GaussianBlur(image, (5, 5), 0)

# Show results
fig, axes = plt.subplots(1, 4, figsize=(20, 5))
axes[0].imshow(image, cmap='gray')
axes[0].set_title('Original Image')
axes[1].imshow(mean_filtered, cmap='gray')
axes[1].set_title('Mean Filter')
axes[2].imshow(median_filtered, cmap='gray')
axes[2].set_title('Median Filter')
axes[3].imshow(gaussian_filtered, cmap='gray')
axes[3].set_title('Gaussian Filter')
for ax in axes:
    ax.axis('off')
plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Read the image
image = cv2.imread('/content/einstein.jpg', cv2.IMREAD_GRAYSCALE)

# Custom sharpening kernel
sharpening_kernel = np.array([[0, -1, 0],
                               [-1, 5,-1],
                               [0, -1, 0]])

# Apply the filter
sharpened_image = cv2.filter2D(image, -1, sharpening_kernel)

# Show results
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(image, cmap='gray')
plt.title('Original Image')
plt.axis('off')
plt.subplot(1, 2, 2)
plt.imshow(sharpened_image, cmap='gray')
plt.title('Sharpened Image')
plt.axis('off')
plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Read the image
image = cv2.imread('/content/einstein.jpg', cv2.IMREAD_GRAYSCALE)

# Apply Laplacian filters with different connectivity
laplacian_4 = cv2.Laplacian(image, cv2.CV_64F, ksize=3, borderType=cv2.BORDER_DEFAULT)
laplacian_8 = cv2.filter2D(image, -1, np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]]))

# Show results
plt.figure(figsize=(10, 5))
plt.subplot(1, 3, 1)
plt.imshow(image, cmap='gray')
plt.title('Original Image')
plt.axis('off')
plt.subplot(1, 3, 2)
plt.imshow(laplacian_4, cmap='gray')
plt.title('Laplacian 4-connected')
plt.axis('off')
plt.subplot(1, 3, 3)
plt.imshow(laplacian_8, cmap='gray')
plt.title('Laplacian 8-connected')
plt.axis('off')
plt.show()

"""Image Enhancement: Arithmetic/Logic Operations
4. Implement image subtraction to detect changes between two images (e.g., before and after an
event).
5. Create a simple image watermarking system using image addition and subtraction.
6. Experiment with image averaging to reduce noise in a sequence of images.
"""



import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load the images
image_before = cv2.imread('/content/star-1-300x168.jpg', cv2.IMREAD_GRAYSCALE)
image_after = cv2.imread('/content/dot-300x168.jpg', cv2.IMREAD_GRAYSCALE)

# Ensure both images are the same size
if image_before.shape != image_after.shape:
    print("Error: Images must have the same dimensions.")
    exit()

# Perform image subtraction
difference = cv2.absdiff(image_before, image_after)

plt.figure(figsize=(10, 5))

# Original images
plt.subplot(1, 3, 1)
plt.imshow(cv2.cvtColor(image_before, cv2.COLOR_BGR2RGB))
plt.title('Before Image')
plt.axis('off')

plt.subplot(1, 3, 2)
plt.imshow(cv2.cvtColor(image_after, cv2.COLOR_BGR2RGB))
plt.title('After Image')
plt.axis('off')

# Difference image
plt.subplot(1, 3, 3)
plt.imshow(difference, cmap='gray')
plt.title('Difference (Subtraction)')
plt.axis('off')

plt.show()
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load the original image and the watermark image
image = cv2.imread('/content/1-500x250-3.jpg')
watermark = cv2.imread('/content/2-500x250-2.jpg', cv2.IMREAD_UNCHANGED)  # Assuming watermark has transparency

# Resize watermark to fit the original image (optional)
watermark_resized = cv2.resize(watermark, (image.shape[1], image.shape[0]))

# Convert watermark to 3 channels if it has an alpha channel (transparency)
if watermark_resized.shape[2] == 4:
    watermark_resized_rgb = cv2.cvtColor(watermark_resized, cv2.COLOR_BGRA2BGR)
else:
    watermark_resized_rgb = watermark_resized

# Add watermark to the original image (using simple addition)
watermarked_image = cv2.addWeighted(image, 1, watermark_resized_rgb, 0.5, 0)

# Display the original image, watermark, resized watermark, watermarked image, and image without watermark
plt.figure(figsize=(15, 10))

# Original image
plt.subplot(2, 3, 1)
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title('Original Image')
plt.axis('off')

# Watermark image
plt.subplot(2, 3, 2)
plt.imshow(cv2.cvtColor(watermark_resized, cv2.COLOR_BGRA2RGBA))  # If watermark has transparency
plt.title('Watermark Image')
plt.axis('off')

# Resized watermark image
plt.subplot(2, 3, 3)
plt.imshow(cv2.cvtColor(watermark_resized_rgb, cv2.COLOR_BGR2RGB))
plt.title('Resized Watermark')
plt.axis('off')

# Watermarked image (image with watermark added)
plt.subplot(2, 3, 4)
plt.imshow(cv2.cvtColor(watermarked_image, cv2.COLOR_BGR2RGB))
plt.title('Watermarked Image')
plt.axis('off')

# Subtract the watermark to reveal the original image
image_without_watermark = cv2.subtract(watermarked_image, watermark_resized_rgb)

plt.subplot(2, 3, 5)
plt.imshow(cv2.cvtColor(image_without_watermark, cv2.COLOR_BGR2RGB))
plt.title('Image Without Watermark')
plt.axis('off')

plt.tight_layout()
plt.show()
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load a sequence of images
image1 = cv2.imread('/content/2-500x250-2.jpg')
image2 = cv2.imread('/content/1-500x250-3.jpg')
image3 = cv2.imread('/content/2-500x250-2.jpg')

# Convert images to grayscale (optional, depending on the application)
image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)
image3_gray = cv2.cvtColor(image3, cv2.COLOR_BGR2GRAY)

# Stack images
images = np.stack([image1_gray, image2_gray, image3_gray], axis=0)

# Average the images to reduce noise
averaged_image = np.mean(images, axis=0).astype(np.uint8)

# Display the original images and the averaged image
plt.figure(figsize=(20, 10))

# Original images
plt.subplot(1, 4, 1)
plt.imshow(image1_gray, cmap='gray')
plt.title('Image 1')
plt.axis('off')

plt.subplot(1, 4, 2)
plt.imshow(image2_gray, cmap='gray')
plt.title('Image 2')
plt.axis('off')

plt.subplot(1, 4, 3)
plt.imshow(image3_gray, cmap='gray')
plt.title('Image 3')
plt.axis('off')

# Averaged image
plt.subplot(1, 4, 4)
plt.imshow(averaged_image, cmap='gray')
plt.title('Averaged Image')
plt.axis('off')

plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load a sequence of images
image1 = cv2.imread('/content/2-500x250-2.jpg')
image2 = cv2.imread('/content/1-500x250-3.jpg')
image3 = cv2.imread('/content/2-500x250-2.jpg')

# Convert images to grayscale (optional, depending on the application)
image1_gray = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
image2_gray = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)
image3_gray = cv2.cvtColor(image3, cv2.COLOR_BGR2GRAY)

# Stack images
images = np.stack([image1_gray, image2_gray, image3_gray], axis=0)

# Average the images to reduce noise
averaged_image = np.mean(images, axis=0).astype(np.uint8)

# Display the original images and the averaged image
plt.figure(figsize=(20, 10))

# Original images
plt.subplot(1, 4, 1)
plt.imshow(image1_gray, cmap='gray')
plt.title('Image 1')
plt.axis('off')

plt.subplot(1, 4, 2)
plt.imshow(image2_gray, cmap='gray')
plt.title('Image 2')
plt.axis('off')

plt.subplot(1, 4, 3)
plt.imshow(image3_gray, cmap='gray')
plt.title('Image 3')
plt.axis('off')

# Averaged image
plt.subplot(1, 4, 4)
plt.imshow(averaged_image, cmap='gray')
plt.title('Averaged Image')
plt.axis('off')

plt.show()

"""Perform Discrete Fourier Transform, Z- transform KL Transform on a gray scale image."""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy.linalg import eigh

# Load a grayscale image
def load_grayscale_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Image not found or unable to read.")
    return image

# 1. Discrete Fourier Transform (DFT)
def perform_dft(image):
    dft = np.fft.fft2(image)
    dft_shift = np.fft.fftshift(dft)  # Shift the zero frequency to the center
    magnitude_spectrum = 20 * np.log(np.abs(dft_shift) + 1)
    return magnitude_spectrum

# 2. Z-Transform (Single-row example)
def perform_z_transform(image, row=0):
    if row >= image.shape[0]:
        raise ValueError("Row index exceeds image dimensions.")
    row_data = image[row, :]
    z_transformed = np.fft.fft(row_data)  # Z-transform is equivalent to Fourier Transform on discrete signals
    magnitude = np.abs(z_transformed)
    return magnitude

# 3. Karhunen-Loève Transform (KL Transform)
def perform_kl_transform(image):
    # Flatten the image into a 2D array (rows as observations)
    image_flatten = image.reshape(-1, image.shape[1])
    covariance_matrix = np.cov(image_flatten, rowvar=False)

    # Compute eigenvalues and eigenvectors
    eigenvalues, eigenvectors = eigh(covariance_matrix)

    # Sort eigenvalues and eigenvectors in descending order
    idx = np.argsort(eigenvalues)[::-1]
    eigenvalues = eigenvalues[idx]
    eigenvectors = eigenvectors[:, idx]

    # Transform the image data
    transformed_data = np.dot(image_flatten, eigenvectors)
    transformed_image = transformed_data.reshape(image.shape)
    return transformed_image

# Main script to test the transforms
def main():
    image_path = "/content/56368408-58561980-61c5-11e9-9800-0678dc02b4e7.png"  # Replace with your image path
    image = load_grayscale_image(image_path)

    # Perform DFT
    dft_result = perform_dft(image)

    # Perform Z-Transform on the first row
    z_transform_result = perform_z_transform(image, row=0)

    # Perform KL Transform
    kl_transform_result = perform_kl_transform(image)

    # Plot results
    plt.figure(figsize=(12, 8))

    # Original Image
    plt.subplot(2, 2, 1)
    plt.title("Original Image")
    plt.imshow(image, cmap='gray')

    # DFT Result
    plt.subplot(2, 2, 2)
    plt.title("DFT Magnitude Spectrum")
    plt.imshow(dft_result, cmap='gray')

    # Z-Transform Magnitude (Plotted as a graph)
    plt.subplot(2, 2, 3)
    plt.title("Z-Transform (Row 0)")
    plt.plot(z_transform_result)

    # KL Transform Result
    plt.subplot(2, 2, 4)
    plt.title("KL Transform Result")
    plt.imshow(kl_transform_result, cmap='gray')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

"""Implement histogram equalization and matching on a grayscale image. Compare the results
visually and quantitatively using metrics like entropy
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy.linalg import eigh
from skimage.exposure import match_histograms
from scipy.stats import entropy

# Load a grayscale image
def load_grayscale_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Image not found or unable to read.")
    return image

# 1. Discrete Fourier Transform (DFT)
def perform_dft(image):
    dft = np.fft.fft2(image)
    dft_shift = np.fft.fftshift(dft)  # Shift the zero frequency to the center
    magnitude_spectrum = 20 * np.log(np.abs(dft_shift) + 1)
    return magnitude_spectrum

# 2. Z-Transform (Single-row example)
def perform_z_transform(image, row=0):
    if row >= image.shape[0]:
        raise ValueError("Row index exceeds image dimensions.")
    row_data = image[row, :]
    z_transformed = np.fft.fft(row_data)  # Z-transform is equivalent to Fourier Transform on discrete signals
    magnitude = np.abs(z_transformed)
    return magnitude

# 3. Karhunen-Loève Transform (KL Transform)
def perform_kl_transform(image):
    # Flatten the image into a 2D array (rows as observations)
    image_flatten = image.reshape(-1, image.shape[1])
    covariance_matrix = np.cov(image_flatten, rowvar=False)

    # Compute eigenvalues and eigenvectors
    eigenvalues, eigenvectors = eigh(covariance_matrix)

    # Sort eigenvalues and eigenvectors in descending order
    idx = np.argsort(eigenvalues)[::-1]
    eigenvalues = eigenvalues[idx]
    eigenvectors = eigenvectors[:, idx]

    # Transform the image data
    transformed_data = np.dot(image_flatten, eigenvectors)
    transformed_image = transformed_data.reshape(image.shape)
    return transformed_image

# 4. Histogram Equalization
def perform_histogram_equalization(image):
    equalized_image = cv2.equalizeHist(image)
    return equalized_image
# 5. Histogram Matching
def perform_histogram_matching(image, reference_image):
    matched_image = match_histograms(image, reference_image, channel_axis=None)  # Use channel_axis instead of multichannel
    return matched_image



# Calculate Entropy
def calculate_entropy(image):
    histogram, _ = np.histogram(image.flatten(), bins=256, range=(0, 256), density=True)
    return entropy(histogram)

# Main script to test the transforms
def main():
    image_path = "/content/einstein.jpg"  # Replace with your image path
    reference_image_path = "/content/images (2).jpeg"  # Replace with your reference image path

    # Load images
    image = load_grayscale_image(image_path)
    reference_image = load_grayscale_image(reference_image_path)

    # Perform DFT
    dft_result = perform_dft(image)

    # Perform Z-Transform on the first row
    z_transform_result = perform_z_transform(image, row=0)

    # Perform KL Transform
    kl_transform_result = perform_kl_transform(image)

    # Perform Histogram Equalization
    equalized_image = perform_histogram_equalization(image)

    # Perform Histogram Matching
    matched_image = perform_histogram_matching(image, reference_image)

    # Calculate Entropy
    original_entropy = calculate_entropy(image)
    equalized_entropy = calculate_entropy(equalized_image)
    matched_entropy = calculate_entropy(matched_image)

    # Print Entropies
    print(f"Original Image Entropy: {original_entropy:.4f}")
    print(f"Equalized Image Entropy: {equalized_entropy:.4f}")
    print(f"Matched Image Entropy: {matched_entropy:.4f}")

    # Plot results
    plt.figure(figsize=(12, 8))

    # Original Image
    plt.subplot(2, 3, 1)
    plt.title("Original Image")
    plt.imshow(image, cmap='gray')

    # DFT Result
    plt.subplot(2, 3, 2)
    plt.title("DFT Magnitude Spectrum")
    plt.imshow(dft_result, cmap='gray')

    # Equalized Image
    plt.subplot(2, 3, 3)
    plt.title("Histogram Equalized")
    plt.imshow(equalized_image, cmap='gray')

    # Matched Image
    plt.subplot(2, 3, 4)
    plt.title("Histogram Matched")
    plt.imshow(matched_image, cmap='gray')

    # KL Transform Result
    plt.subplot(2, 3, 5)
    plt.title("KL Transform Result")
    plt.imshow(kl_transform_result, cmap='gray')

    # Z-Transform Magnitude (Plotted as a graph)
    plt.subplot(2, 3, 6)
    plt.title("Z-Transform (Row 0)")
    plt.plot(z_transform_result)

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

"""Design a contrast enhancement technique for images with low contrast. Apply it to a real-
world image and evaluate its effectiveness.
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.exposure import match_histograms

# Load a grayscale image
def load_grayscale_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Image not found or unable to read.")
    return image

# Contrast Enhancement using CLAHE and Gamma Correction
def contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2):
    # 1. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    enhanced_image = clahe.apply(image)

    # 2. Apply Gamma Correction
    gamma_corrected = np.power(enhanced_image / 255.0, gamma) * 255
    gamma_corrected = np.clip(gamma_corrected, 0, 255).astype(np.uint8)

    return gamma_corrected

# Evaluate contrast enhancement using CNR (Contrast-to-Noise Ratio)
def compute_cnr(original, enhanced):
    original_mean = np.mean(original)
    enhanced_mean = np.mean(enhanced)

    original_std = np.std(original)
    enhanced_std = np.std(enhanced)

    cnr_original = original_mean / original_std if original_std != 0 else 0
    cnr_enhanced = enhanced_mean / enhanced_std if enhanced_std != 0 else 0

    return cnr_original, cnr_enhanced

# Main script to test the contrast enhancement
def main():
    image_path = "/content/images (3).jpeg"  # Replace with your image path
    image = load_grayscale_image(image_path)

    # Apply Contrast Enhancement
    enhanced_image = contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2)

    # Evaluate Effectiveness
    cnr_original, cnr_enhanced = compute_cnr(image, enhanced_image)

    print(f"CNR (Original): {cnr_original:.4f}")
    print(f"CNR (Enhanced): {cnr_enhanced:.4f}")

    # Plot results
    plt.figure(figsize=(12, 6))

    # Original Image
    plt.subplot(1, 2, 1)
    plt.title("Original Image")
    plt.imshow(image, cmap='gray')
    plt.axis('off')

    # Enhanced Image
    plt.subplot(1, 2, 2)
    plt.title("Enhanced Image")
    plt.imshow(enhanced_image, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.exposure import match_histograms

# Load a grayscale image
def load_grayscale_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Image not found or unable to read.")
    return image

# Contrast Enhancement using CLAHE and Gamma Correction
def contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2):
    # 1. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    enhanced_image = clahe.apply(image)

    # 2. Apply Gamma Correction
    gamma_corrected = np.power(enhanced_image / 255.0, gamma) * 255
    gamma_corrected = np.clip(gamma_corrected, 0, 255).astype(np.uint8)

    return gamma_corrected

# Evaluate contrast enhancement using CNR (Contrast-to-Noise Ratio)
def compute_cnr(original, enhanced):
    original_mean = np.mean(original)
    enhanced_mean = np.mean(enhanced)

    original_std = np.std(original)
    enhanced_std = np.std(enhanced)

    cnr_original = original_mean / original_std if original_std != 0 else 0
    cnr_enhanced = enhanced_mean / enhanced_std if enhanced_std != 0 else 0

    return cnr_original, cnr_enhanced

# Main script to test the contrast enhancement
def main():
    image_path = "/content/qKZBg.png"  # Replace with your image path
    image = load_grayscale_image(image_path)

    # Apply Contrast Enhancement
    enhanced_image = contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2)

    # Evaluate Effectiveness
    cnr_original, cnr_enhanced = compute_cnr(image, enhanced_image)

    print(f"CNR (Original): {cnr_original:.4f}")
    print(f"CNR (Enhanced): {cnr_enhanced:.4f}")

    # Plot results
    plt.figure(figsize=(12, 6))

    # Original Image
    plt.subplot(1, 2, 1)
    plt.title("Original Image")
    plt.imshow(image, cmap='gray')
    plt.axis('off')

    # Enhanced Image
    plt.subplot(1, 2, 2)
    plt.title("Enhanced Image")
    plt.imshow(enhanced_image, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

"""Implement the 2D Discrete Fourier Transform (DFT) and its inverse"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.exposure import match_histograms

# Load a grayscale image
def load_grayscale_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Image not found or unable to read.")
    return image

# Contrast Enhancement using CLAHE and Gamma Correction
def contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2):
    # 1. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    enhanced_image = clahe.apply(image)

    # 2. Apply Gamma Correction
    gamma_corrected = np.power(enhanced_image / 255.0, gamma) * 255
    gamma_corrected = np.clip(gamma_corrected, 0, 255).astype(np.uint8)

    return gamma_corrected

# Evaluate contrast enhancement using CNR (Contrast-to-Noise Ratio)
def compute_cnr(original, enhanced):
    original_mean = np.mean(original)
    enhanced_mean = np.mean(enhanced)

    original_std = np.std(original)
    enhanced_std = np.std(enhanced)

    cnr_original = original_mean / original_std if original_std != 0 else 0
    cnr_enhanced = enhanced_mean / enhanced_std if enhanced_std != 0 else 0

    return cnr_original, cnr_enhanced

# Perform 2D Discrete Fourier Transform
def perform_dft(image):
    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)
    magnitude_spectrum = 20 * np.log(np.abs(dft_shifted) + 1)  # Logarithmic scale for visualization
    return dft, dft_shifted, magnitude_spectrum

# Perform Inverse 2D Discrete Fourier Transform
def perform_idft(dft_shifted):
    idft_shifted = np.fft.ifftshift(dft_shifted)
    reconstructed_image = np.fft.ifft2(idft_shifted)
    reconstructed_image = np.abs(reconstructed_image)
    return reconstructed_image

# Main script to test the contrast enhancement and DFT
def main():
    image_path = "/content/einstein.jpg"  # Replace with your image path
    image = load_grayscale_image(image_path)

    # Apply Contrast Enhancement
    enhanced_image = contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2)

    # Evaluate Effectiveness
    cnr_original, cnr_enhanced = compute_cnr(image, enhanced_image)

    print(f"CNR (Original): {cnr_original:.4f}")
    print(f"CNR (Enhanced): {cnr_enhanced:.4f}")

    # Perform 2D DFT
    dft, dft_shifted, magnitude_spectrum = perform_dft(image)

    # Perform Inverse DFT
    reconstructed_image = perform_idft(dft_shifted)

    # Plot results
    plt.figure(figsize=(15, 10))

    # Original Image
    plt.subplot(2, 2, 1)
    plt.title("Original Image")
    plt.imshow(image, cmap='gray')
    plt.axis('off')

    # Enhanced Image
    plt.subplot(2, 2, 2)
    plt.title("Enhanced Image")
    plt.imshow(enhanced_image, cmap='gray')
    plt.axis('off')

    # DFT Magnitude Spectrum
    plt.subplot(2, 2, 3)
    plt.title("DFT Magnitude Spectrum")
    plt.imshow(magnitude_spectrum, cmap='gray')
    plt.axis('off')

    # Reconstructed Image
    plt.subplot(2, 2, 4)
    plt.title("Reconstructed Image (Inverse DFT)")
    plt.imshow(reconstructed_image, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

"""Design low-pass, high-pass, and band-pass filters in the frequency domain. Apply them to an
image and analyze the results
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.exposure import match_histograms

# Load a grayscale image
def load_grayscale_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Image not found or unable to read.")
    return image

# Contrast Enhancement using CLAHE and Gamma Correction
def contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2):
    # 1. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    enhanced_image = clahe.apply(image)

    # 2. Apply Gamma Correction
    gamma_corrected = np.power(enhanced_image / 255.0, gamma) * 255
    gamma_corrected = np.clip(gamma_corrected, 0, 255).astype(np.uint8)

    return gamma_corrected

# Evaluate contrast enhancement using CNR (Contrast-to-Noise Ratio)
def compute_cnr(original, enhanced):
    original_mean = np.mean(original)
    enhanced_mean = np.mean(enhanced)

    original_std = np.std(original)
    enhanced_std = np.std(enhanced)

    cnr_original = original_mean / original_std if original_std != 0 else 0
    cnr_enhanced = enhanced_mean / enhanced_std if enhanced_std != 0 else 0

    return cnr_original, cnr_enhanced

# Perform 2D Discrete Fourier Transform
def perform_dft(image):
    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)
    magnitude_spectrum = 20 * np.log(np.abs(dft_shifted) + 1)  # Logarithmic scale for visualization
    return dft, dft_shifted, magnitude_spectrum

# Perform Inverse 2D Discrete Fourier Transform
def perform_idft(dft_shifted):
    idft_shifted = np.fft.ifftshift(dft_shifted)
    reconstructed_image = np.fft.ifft2(idft_shifted)
    reconstructed_image = np.abs(reconstructed_image)
    return reconstructed_image

# Design and apply frequency domain filters
def apply_frequency_filters(image):
    rows, cols = image.shape
    crow, ccol = rows // 2, cols // 2

    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)

    # Low-pass filter
    low_pass = np.zeros((rows, cols), np.uint8)
    low_pass[crow-30:crow+30, ccol-30:ccol+30] = 1
    dft_low_pass = dft_shifted * low_pass
    low_pass_image = perform_idft(dft_low_pass)

    # High-pass filter
    high_pass = np.ones((rows, cols), np.uint8)
    high_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_high_pass = dft_shifted * high_pass
    high_pass_image = perform_idft(dft_high_pass)

    # Band-pass filter
    band_pass = np.zeros((rows, cols), np.uint8)
    band_pass[crow-50:crow+50, ccol-50:ccol+50] = 1
    band_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_band_pass = dft_shifted * band_pass
    band_pass_image = perform_idft(dft_band_pass)

    return low_pass_image, high_pass_image, band_pass_image

# Main script to test the contrast enhancement and DFT
def main():
    image_path = "/content/einstein.jpg"  # Replace with your image path
    image = load_grayscale_image(image_path)

    # Apply Contrast Enhancement
    enhanced_image = contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2)

    # Evaluate Effectiveness
    cnr_original, cnr_enhanced = compute_cnr(image, enhanced_image)

    print(f"CNR (Original): {cnr_original:.4f}")
    print(f"CNR (Enhanced): {cnr_enhanced:.4f}")

    # Perform 2D DFT
    dft, dft_shifted, magnitude_spectrum = perform_dft(image)

    # Perform Inverse DFT
    reconstructed_image = perform_idft(dft_shifted)

    # Apply frequency domain filters
    low_pass_image, high_pass_image, band_pass_image = apply_frequency_filters(image)

    # Plot results
    plt.figure(figsize=(15, 10))

    # Original Image
    plt.subplot(2, 3, 1)
    plt.title("Original Image")
    plt.imshow(image, cmap='gray')
    plt.axis('off')

    # DFT Magnitude Spectrum
    plt.subplot(2, 3, 2)
    plt.title("DFT Magnitude Spectrum")
    plt.imshow(magnitude_spectrum, cmap='gray')
    plt.axis('off')

    # Reconstructed Image
    plt.subplot(2, 3, 3)
    plt.title("Reconstructed Image (Inverse DFT)")
    plt.imshow(reconstructed_image, cmap='gray')
    plt.axis('off')

    # Low-pass Filtered Image
    plt.subplot(2, 3, 4)
    plt.title("Low-pass Filter")
    plt.imshow(low_pass_image, cmap='gray')
    plt.axis('off')

    # High-pass Filtered Image
    plt.subplot(2, 3, 5)
    plt.title("High-pass Filter")
    plt.imshow(high_pass_image, cmap='gray')
    plt.axis('off')

    # Band-pass Filtered Image
    plt.subplot(2, 3, 6)
    plt.title("Band-pass Filter")
    plt.imshow(band_pass_image, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.exposure import match_histograms

# Load a grayscale image
def load_grayscale_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Image not found or unable to read.")
    return image

# Contrast Enhancement using CLAHE and Gamma Correction
def contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2):
    # 1. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    enhanced_image = clahe.apply(image)

    # 2. Apply Gamma Correction
    gamma_corrected = np.power(enhanced_image / 255.0, gamma) * 255
    gamma_corrected = np.clip(gamma_corrected, 0, 255).astype(np.uint8)

    return gamma_corrected

# Evaluate contrast enhancement using CNR (Contrast-to-Noise Ratio)
def compute_cnr(original, enhanced):
    original_mean = np.mean(original)
    enhanced_mean = np.mean(enhanced)

    original_std = np.std(original)
    enhanced_std = np.std(enhanced)

    cnr_original = original_mean / original_std if original_std != 0 else 0
    cnr_enhanced = enhanced_mean / enhanced_std if enhanced_std != 0 else 0

    return cnr_original, cnr_enhanced

# Perform 2D Discrete Fourier Transform
def perform_dft(image):
    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)
    magnitude_spectrum = 20 * np.log(np.abs(dft_shifted) + 1)  # Logarithmic scale for visualization
    return dft, dft_shifted, magnitude_spectrum

# Perform Inverse 2D Discrete Fourier Transform
def perform_idft(dft_shifted):
    idft_shifted = np.fft.ifftshift(dft_shifted)
    reconstructed_image = np.fft.ifft2(idft_shifted)
    reconstructed_image = np.abs(reconstructed_image)
    return reconstructed_image

# Design and apply frequency domain filters
def apply_frequency_filters(image):
    rows, cols = image.shape
    crow, ccol = rows // 2, cols // 2

    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)

    # Low-pass filter
    low_pass = np.zeros((rows, cols), np.uint8)
    low_pass[crow-30:crow+30, ccol-30:ccol+30] = 1
    dft_low_pass = dft_shifted * low_pass
    low_pass_image = perform_idft(dft_low_pass)

    # High-pass filter
    high_pass = np.ones((rows, cols), np.uint8)
    high_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_high_pass = dft_shifted * high_pass
    high_pass_image = perform_idft(dft_high_pass)

    # Band-pass filter
    band_pass = np.zeros((rows, cols), np.uint8)
    band_pass[crow-50:crow+50, ccol-50:ccol+50] = 1
    band_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_band_pass = dft_shifted * band_pass
    band_pass_image = perform_idft(dft_band_pass)

    return low_pass_image, high_pass_image, band_pass_image

# Main script to test the contrast enhancement and DFT
def main():
    image_path = "/content/MainAfter.jpg"  # Replace with your image path
    image = load_grayscale_image(image_path)

    # Apply Contrast Enhancement
    enhanced_image = contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2)

    # Evaluate Effectiveness
    cnr_original, cnr_enhanced = compute_cnr(image, enhanced_image)

    print(f"CNR (Original): {cnr_original:.4f}")
    print(f"CNR (Enhanced): {cnr_enhanced:.4f}")

    # Perform 2D DFT
    dft, dft_shifted, magnitude_spectrum = perform_dft(image)

    # Perform Inverse DFT
    reconstructed_image = perform_idft(dft_shifted)

    # Apply frequency domain filters
    low_pass_image, high_pass_image, band_pass_image = apply_frequency_filters(image)

    # Plot results
    plt.figure(figsize=(15, 10))

    # Original Image
    plt.subplot(2, 3, 1)
    plt.title("Original Image")
    plt.imshow(image, cmap='gray')
    plt.axis('off')

    # DFT Magnitude Spectrum
    plt.subplot(2, 3, 2)
    plt.title("DFT Magnitude Spectrum")
    plt.imshow(magnitude_spectrum, cmap='gray')
    plt.axis('off')

    # Reconstructed Image
    plt.subplot(2, 3, 3)
    plt.title("Reconstructed Image (Inverse DFT)")
    plt.imshow(reconstructed_image, cmap='gray')
    plt.axis('off')

    # Low-pass Filtered Image
    plt.subplot(2, 3, 4)
    plt.title("Low-pass Filter")
    plt.imshow(low_pass_image, cmap='gray')
    plt.axis('off')

    # High-pass Filtered Image
    plt.subplot(2, 3, 5)
    plt.title("High-pass Filter")
    plt.imshow(high_pass_image, cmap='gray')
    plt.axis('off')

    # Band-pass Filtered Image
    plt.subplot(2, 3, 6)
    plt.title("Band-pass Filter")
    plt.imshow(band_pass_image, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

"""Implement homomorphic filtering and apply it to an image with uneven illumination."""

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Step 1: Read the image
image = cv2.imread('/content/56368408-58561980-61c5-11e9-9800-0678dc02b4e7.png', cv2.IMREAD_GRAYSCALE)

# Step 2: Log Transformation
log_image = np.log1p(np.float32(image))

# Step 3: Fourier Transform
dft = cv2.dft(log_image, flags=cv2.DFT_COMPLEX_OUTPUT)
dft_shift = np.fft.fftshift(dft)

# Step 4: Create High-Pass Filter
rows, cols = image.shape
crow, ccol = rows // 2, cols // 2

# Create a circular high-pass filter
radius = 30  # Adjust the radius as needed
mask = np.ones((rows, cols, 2), np.float32)
cv2.circle(mask, (ccol, crow), radius, (0, 0, 0), -1)

# Step 5: Apply the filter
filtered_dft = dft_shift * mask

# Step 6: Inverse Fourier Transform
dft_ishift = np.fft.ifftshift(filtered_dft)
img_back = cv2.idft(dft_ishift)
img_back = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])

# Step 7: Exponential Transformation
result_image = np.expm1(img_back)

# Step 8: Normalize the Resulting Image
result_image = np.uint8(cv2.normalize(result_image, None, 0, 255, cv2.NORM_MINMAX))

# Step 9: Display the results
plt.figure(figsize=(10, 5))
plt.subplot(1, 3, 1), plt.imshow(image, cmap='gray'), plt.title('Original Image')
plt.subplot(1, 3, 2), plt.imshow(log_image, cmap='gray'), plt.title('Log-Transformed Image')
plt.subplot(1, 3, 3), plt.imshow(result_image, cmap='gray'), plt.title('Homomorphic Filtered Image')
plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt

def homomorphic_filtering(image_path):
    # Load image
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    # Convert to float32
    img_float = np.float32(img)

    # Step 1: Logarithmic Transformation
    log_img = np.log1p(img_float)

    # Step 2: Fourier Transform
    f = np.fft.fft2(log_img)
    fshift = np.fft.fftshift(f)

    # Step 3: Create a high-pass filter
    rows, cols = img.shape
    crow, ccol = rows // 2, cols // 2
    mask = np.ones((rows, cols), dtype=np.float32)

    r = 30  # radius of the high-pass filter
    center = [crow, ccol]

    # Create a meshgrid of the frequency space
    x = np.fft.fftfreq(cols, 1 / cols)
    y = np.fft.fftfreq(rows, 1 / rows)
    X, Y = np.meshgrid(x, y)

    # Compute the distance from the center of the frequency domain
    distance = np.sqrt((X - center[0])**2 + (Y - center[1])**2)

    # Set mask to 0 where the distance is less than the radius (low-pass region)
    mask[distance < r] = 0

    # Step 4: Apply the high-pass filter to the frequency domain
    fshift_filtered = fshift * mask

    # Step 5: Inverse Fourier Transform to get back to spatial domain
    f_ishift = np.fft.ifftshift(fshift_filtered)
    img_back = np.fft.ifft2(f_ishift)
    img_back = np.real(img_back)

    # Step 6: Exponentiation to undo log transformation
    img_back = np.expm1(img_back)

    # Normalize to the range [0, 255]
    img_back = np.uint8(np.clip(img_back, 0, 255))

    # Display the results
    plt.figure(figsize=(10, 10))

    # Original image
    plt.subplot(1, 2, 1)
    plt.imshow(img, cmap='gray')
    plt.title('Original Image')
    plt.axis('off')

    # Homomorphic filtering result
    plt.subplot(1, 2, 2)
    plt.imshow(img_back, cmap='gray')
    plt.title('Homomorphic Filtered Image')
    plt.axis('off')

    plt.show()

# Apply homomorphic filtering to an image with uneven illumination
image_path = '/content/MainAfter.jpg'  # Replace with your image path
homomorphic_filtering(image_path)

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.exposure import match_histograms

# Load a grayscale image
def load_grayscale_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Image not found or unable to read.")
    return image

# Contrast Enhancement using CLAHE and Gamma Correction
def contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2):
    # 1. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    enhanced_image = clahe.apply(image)

    # 2. Apply Gamma Correction
    gamma_corrected = np.power(enhanced_image / 255.0, gamma) * 255
    gamma_corrected = np.clip(gamma_corrected, 0, 255).astype(np.uint8)

    return gamma_corrected

# Evaluate contrast enhancement using CNR (Contrast-to-Noise Ratio)
def compute_cnr(original, enhanced):
    original_mean = np.mean(original)
    enhanced_mean = np.mean(enhanced)

    original_std = np.std(original)
    enhanced_std = np.std(enhanced)

    cnr_original = original_mean / original_std if original_std != 0 else 0
    cnr_enhanced = enhanced_mean / enhanced_std if enhanced_std != 0 else 0

    return cnr_original, cnr_enhanced

# Perform 2D Discrete Fourier Transform
def perform_dft(image):
    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)
    magnitude_spectrum = 20 * np.log(np.abs(dft_shifted) + 1)  # Logarithmic scale for visualization
    return dft, dft_shifted, magnitude_spectrum

# Perform Inverse 2D Discrete Fourier Transform
def perform_idft(dft_shifted):
    idft_shifted = np.fft.ifftshift(dft_shifted)
    reconstructed_image = np.fft.ifft2(idft_shifted)
    reconstructed_image = np.abs(reconstructed_image)
    return reconstructed_image

# Design and apply frequency domain filters
def apply_frequency_filters(image):
    rows, cols = image.shape
    crow, ccol = rows // 2, cols // 2

    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)

    # Low-pass filter
    low_pass = np.zeros((rows, cols), np.uint8)
    low_pass[crow-30:crow+30, ccol-30:ccol+30] = 1
    dft_low_pass = dft_shifted * low_pass
    low_pass_image = perform_idft(dft_low_pass)

    # High-pass filter
    high_pass = np.ones((rows, cols), np.uint8)
    high_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_high_pass = dft_shifted * high_pass
    high_pass_image = perform_idft(dft_high_pass)

    # Band-pass filter
    band_pass = np.zeros((rows, cols), np.uint8)
    band_pass[crow-50:crow+50, ccol-50:ccol+50] = 1
    band_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_band_pass = dft_shifted * band_pass
    band_pass_image = perform_idft(dft_band_pass)

    return low_pass_image, high_pass_image, band_pass_image

# Perform Homomorphic Filtering
def homomorphic_filtering(image, gamma_low=0.5, gamma_high=2.0, cutoff=30):
    rows, cols = image.shape
    crow, ccol = rows // 2, cols // 2

    # Convert to log domain
    log_image = np.log1p(np.array(image, dtype=np.float64))

    # Apply DFT
    dft = np.fft.fft2(log_image)
    dft_shifted = np.fft.fftshift(dft)

    # Create Gaussian high-pass filter
    x, y = np.meshgrid(np.linspace(-ccol, ccol, cols), np.linspace(-crow, crow, rows))
    radius = np.sqrt(x**2 + y**2)
    filter_mask = 1 - np.exp(-(radius**2) / (2 * (cutoff**2)))

    # Apply filter
    dft_filtered = dft_shifted * ((gamma_high - gamma_low) * filter_mask + gamma_low)

    # Inverse DFT
    idft_shifted = np.fft.ifftshift(dft_filtered)
    filtered_image = np.fft.ifft2(idft_shifted)
    filtered_image = np.exp(np.abs(filtered_image)) - 1

    # Normalize to 8-bit range
    filtered_image = np.clip(filtered_image, 0, 255)
    filtered_image = filtered_image.astype(np.uint8)

    return filtered_image

# Main script to test the contrast enhancement, DFT, and homomorphic filtering
def main():
    image_path = "/content/MainAfter.jpg"  # Replace with your image path
    image = load_grayscale_image(image_path)

    # Apply Contrast Enhancement
    enhanced_image = contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2)

    # Evaluate Effectiveness
    cnr_original, cnr_enhanced = compute_cnr(image, enhanced_image)

    print(f"CNR (Original): {cnr_original:.4f}")
    print(f"CNR (Enhanced): {cnr_enhanced:.4f}")

    # Perform 2D DFT
    dft, dft_shifted, magnitude_spectrum = perform_dft(image)

    # Perform Inverse DFT
    reconstructed_image = perform_idft(dft_shifted)

    # Apply frequency domain filters
    low_pass_image, high_pass_image, band_pass_image = apply_frequency_filters(image)

    # Apply Homomorphic Filtering
    homomorphic_image = homomorphic_filtering(image)

    # Plot results
    plt.figure(figsize=(15, 12))

    # Original Image
    plt.subplot(2, 4, 1)
    plt.title("Original Image")
    plt.imshow(image, cmap='gray')
    plt.axis('off')

    # DFT Magnitude Spectrum
    plt.subplot(2, 4, 2)
    plt.title("DFT Magnitude Spectrum")
    plt.imshow(magnitude_spectrum, cmap='gray')
    plt.axis('off')

    # Reconstructed Image
    plt.subplot(2, 4, 3)
    plt.title("Reconstructed Image (Inverse DFT)")
    plt.imshow(reconstructed_image, cmap='gray')
    plt.axis('off')

    # Low-pass Filtered Image
    plt.subplot(2, 4, 4)
    plt.title("Low-pass Filter")
    plt.imshow(low_pass_image, cmap='gray')
    plt.axis('off')

    # High-pass Filtered Image
    plt.subplot(2, 4, 5)
    plt.title("High-pass Filter")
    plt.imshow(high_pass_image, cmap='gray')
    plt.axis('off')

    # Band-pass Filtered Image
    plt.subplot(2, 4, 6)
    plt.title("Band-pass Filter")
    plt.imshow(band_pass_image, cmap='gray')
    plt.axis('off')

    # Homomorphic Filtered Image
    plt.subplot(2, 4, 7)
    plt.title("Homomorphic Filter")
    plt.imshow(homomorphic_image, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.exposure import match_histograms

# Load a grayscale image
def load_grayscale_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Image not found or unable to read.")
    return image

# Contrast Enhancement using CLAHE and Gamma Correction
def contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2):
    # 1. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    enhanced_image = clahe.apply(image)

    # 2. Apply Gamma Correction
    gamma_corrected = np.power(enhanced_image / 255.0, gamma) * 255
    gamma_corrected = np.clip(gamma_corrected, 0, 255).astype(np.uint8)

    return gamma_corrected

# Evaluate contrast enhancement using CNR (Contrast-to-Noise Ratio)
def compute_cnr(original, enhanced):
    original_mean = np.mean(original)
    enhanced_mean = np.mean(enhanced)

    original_std = np.std(original)
    enhanced_std = np.std(enhanced)

    cnr_original = original_mean / original_std if original_std != 0 else 0
    cnr_enhanced = enhanced_mean / enhanced_std if enhanced_std != 0 else 0

    return cnr_original, cnr_enhanced

# Perform 2D Discrete Fourier Transform
def perform_dft(image):
    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)
    magnitude_spectrum = 20 * np.log(np.abs(dft_shifted) + 1)  # Logarithmic scale for visualization
    return dft, dft_shifted, magnitude_spectrum

# Perform Inverse 2D Discrete Fourier Transform
def perform_idft(dft_shifted):
    idft_shifted = np.fft.ifftshift(dft_shifted)
    reconstructed_image = np.fft.ifft2(idft_shifted)
    reconstructed_image = np.abs(reconstructed_image)
    return reconstructed_image

# Design and apply frequency domain filters
def apply_frequency_filters(image):
    rows, cols = image.shape
    crow, ccol = rows // 2, cols // 2

    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)

    # Low-pass filter
    low_pass = np.zeros((rows, cols), np.uint8)
    low_pass[crow-30:crow+30, ccol-30:ccol+30] = 1
    dft_low_pass = dft_shifted * low_pass
    low_pass_image = perform_idft(dft_low_pass)

    # High-pass filter
    high_pass = np.ones((rows, cols), np.uint8)
    high_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_high_pass = dft_shifted * high_pass
    high_pass_image = perform_idft(dft_high_pass)

    # Band-pass filter
    band_pass = np.zeros((rows, cols), np.uint8)
    band_pass[crow-50:crow+50, ccol-50:ccol+50] = 1
    band_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_band_pass = dft_shifted * band_pass
    band_pass_image = perform_idft(dft_band_pass)

    return low_pass_image, high_pass_image, band_pass_image

# Perform Homomorphic Filtering
def homomorphic_filtering(image, gamma_low=0.5, gamma_high=2.0, cutoff=30):
    rows, cols = image.shape
    crow, ccol = rows // 2, cols // 2

    # Convert to log domain
    log_image = np.log1p(np.array(image, dtype=np.float64))

    # Apply DFT
    dft = np.fft.fft2(log_image)
    dft_shifted = np.fft.fftshift(dft)

    # Create Gaussian high-pass filter
    x, y = np.meshgrid(np.linspace(-ccol, ccol, cols), np.linspace(-crow, crow, rows))
    radius = np.sqrt(x**2 + y**2)
    filter_mask = 1 - np.exp(-(radius**2) / (2 * (cutoff**2)))

    # Apply filter
    dft_filtered = dft_shifted * ((gamma_high - gamma_low) * filter_mask + gamma_low)

    # Inverse DFT
    idft_shifted = np.fft.ifftshift(dft_filtered)
    filtered_image = np.fft.ifft2(idft_shifted)
    filtered_image = np.exp(np.abs(filtered_image)) - 1

    # Normalize to 8-bit range
    filtered_image = np.clip(filtered_image, 0, 255)
    filtered_image = filtered_image.astype(np.uint8)

    return filtered_image

# Main script to test the contrast enhancement, DFT, and homomorphic filtering
def main():
    image_path = "/content/56368408-58561980-61c5-11e9-9800-0678dc02b4e7.png"  # Replace with your image path
    image = load_grayscale_image(image_path)

    # Apply Contrast Enhancement
    enhanced_image = contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2)

    # Evaluate Effectiveness
    cnr_original, cnr_enhanced = compute_cnr(image, enhanced_image)

    print(f"CNR (Original): {cnr_original:.4f}")
    print(f"CNR (Enhanced): {cnr_enhanced:.4f}")

    # Perform 2D DFT
    dft, dft_shifted, magnitude_spectrum = perform_dft(image)

    # Perform Inverse DFT
    reconstructed_image = perform_idft(dft_shifted)

    # Apply frequency domain filters
    low_pass_image, high_pass_image, band_pass_image = apply_frequency_filters(image)

    # Apply Homomorphic Filtering
    homomorphic_image = homomorphic_filtering(image)

    # Plot results
    plt.figure(figsize=(15, 12))

    # Original Image
    plt.subplot(2, 4, 1)
    plt.title("Original Image")
    plt.imshow(image, cmap='gray')
    plt.axis('off')

    # DFT Magnitude Spectrum
    plt.subplot(2, 4, 2)
    plt.title("DFT Magnitude Spectrum")
    plt.imshow(magnitude_spectrum, cmap='gray')
    plt.axis('off')

    # Reconstructed Image
    plt.subplot(2, 4, 3)
    plt.title("Reconstructed Image (Inverse DFT)")
    plt.imshow(reconstructed_image, cmap='gray')
    plt.axis('off')

    # Low-pass Filtered Image
    plt.subplot(2, 4, 4)
    plt.title("Low-pass Filter")
    plt.imshow(low_pass_image, cmap='gray')
    plt.axis('off')

    # High-pass Filtered Image
    plt.subplot(2, 4, 5)
    plt.title("High-pass Filter")
    plt.imshow(high_pass_image, cmap='gray')
    plt.axis('off')

    # Band-pass Filtered Image
    plt.subplot(2, 4, 6)
    plt.title("Band-pass Filter")
    plt.imshow(band_pass_image, cmap='gray')
    plt.axis('off')

    # Homomorphic Filtered Image
    plt.subplot(2, 4, 7)
    plt.title("Homomorphic Filter")
    plt.imshow(homomorphic_image, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

import cv2
import numpy as np
import matplotlib.pyplot as plt

def homomorphic_filtering(image_path):
    # Load image
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    # Convert to float32
    img_float = np.float32(img)

    # Step 1: Logarithmic Transformation
    log_img = np.log1p(img_float)

    # Step 2: Fourier Transform
    f = np.fft.fft2(log_img)
    fshift = np.fft.fftshift(f)

    # Step 3: Create a high-pass filter
    rows, cols = img.shape
    crow, ccol = rows // 2, cols // 2
    mask = np.ones((rows, cols), dtype=np.float32)

    r = 30  # radius of the high-pass filter
    center = [crow, ccol]

    # Create a meshgrid of the frequency space
    x = np.fft.fftfreq(cols, 1 / cols)
    y = np.fft.fftfreq(rows, 1 / rows)
    X, Y = np.meshgrid(x, y)

    # Compute the distance from the center of the frequency domain
    distance = np.sqrt((X - center[0])**2 + (Y - center[1])**2)

    # Set mask to 0 where the distance is less than the radius (low-pass region)
    mask[distance < r] = 0

    # Step 4: Apply the high-pass filter to the frequency domain
    fshift_filtered = fshift * mask

    # Step 5: Inverse Fourier Transform to get back to spatial domain
    f_ishift = np.fft.ifftshift(fshift_filtered)
    img_back = np.fft.ifft2(f_ishift)
    img_back = np.real(img_back)

    # Step 6: Exponentiation to undo log transformation
    img_back = np.expm1(img_back)

    # Normalize to the range [0, 255]
    img_back = np.uint8(np.clip(img_back, 0, 255))

    # Display the results
    plt.figure(figsize=(10, 10))

    # Original image
    plt.subplot(1, 2, 1)
    plt.imshow(img, cmap='gray')
    plt.title('Original Image')
    plt.axis('off')

    # Homomorphic filtering result
    plt.subplot(1, 2, 2)
    plt.imshow(img_back, cmap='gray')
    plt.title('Homomorphic Filtered Image')
    plt.axis('off')

    plt.show()

# Apply homomorphic filtering to an image with uneven illumination
image_path = 'your_image_path.jpg'  # Replace with your image path
homomorphic_filtering(image_path)

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load the image
image = cv2.imread('/content/56368408-58561980-61c5-11e9-9800-0678dc02b4e7.png', cv2.IMREAD_GRAYSCALE)

# Convert the image to float32 and normalize
image_float = np.float32(image) + 1.0

# Log transformation to separate illumination and reflectance
log_image = np.log(image_float)

# Apply Fourier Transform
f_image = np.fft.fft2(log_image)
fshift = np.fft.fftshift(f_image)

# Create a high-pass filter (Gaussian filter for low-frequency removal)
rows, cols = image.shape
crow, ccol = rows // 2, cols // 2
d0 = 30  # cutoff frequency
x = np.arange(0, cols)
y = np.arange(0, rows)
X, Y = np.meshgrid(x, y)
distance = np.sqrt((X - ccol) ** 2 + (Y - crow) ** 2)
hp_filter = np.exp(-(distance ** 2) / (2 * (d0 ** 2)))

# Apply the filter in the frequency domain
fshift_hp = fshift * hp_filter

# Inverse FFT to get back to the spatial domain
f_ishift = np.fft.ifftshift(fshift_hp)
image_hp = np.fft.ifft2(f_ishift)
image_hp = np.real(image_hp)

# Exponentiate to reverse the log transformation
image_result = np.exp(image_hp) - 1.0

# Normalize the image to be in range [0, 255]
image_result = np.uint8(np.clip(image_result, 0, 255))

# Display the original and filtered images
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(image, cmap='gray')
plt.title('Original Image')
plt.subplot(1, 2, 2)
plt.imshow(image_result, cmap='gray')
plt.title('Filtered Image')
plt.show()

import numpy as np
import cv2
import matplotlib.pyplot as plt

# Function for RGB to HSI conversion
def rgb_to_hsi(rgb_image):
    # Normalize RGB values to [0,1]
    rgb_image = rgb_image / 255.0
    r, g, b = rgb_image[:,:,0], rgb_image[:,:,1], rgb_image[:,:,2]

    # Compute the intensity component
    intensity = (r + g + b) / 3

    # Compute the saturation component
    min_rgb = np.minimum(r, np.minimum(g, b))
    saturation = 1 - (3 / (r + g + b + 1e-6)) * min_rgb

    # Compute the hue component
    numerator = 0.5 * ((r - g) + (r - b))
    denominator = np.sqrt((r - g)**2 + (r - b)*(g - b))
    theta = np.arccos(numerator / (denominator + 1e-6))

    hue = np.degrees(theta)

    # Adjust hue based on RGB components
    hue[b > g] = 360 - hue[b > g]

    return np.stack((hue, saturation, intensity), axis=-1)

# Function for RGB to YCbCr conversion
def rgb_to_ycbcr(rgb_image):
    # Normalize RGB values to [0, 255]
    rgb_image = np.float32(rgb_image)

    # YCbCr Conversion Formula
    y = 0.299 * rgb_image[:,:,0] + 0.587 * rgb_image[:,:,1] + 0.114 * rgb_image[:,:,2]
    cb = -0.168736 * rgb_image[:,:,0] - 0.331264 * rgb_image[:,:,1] + 0.5 * rgb_image[:,:,2] + 128
    cr = 0.5 * rgb_image[:,:,0] - 0.418688 * rgb_image[:,:,1] - 0.081312 * rgb_image[:,:,2] + 128

    return np.stack((y, cb, cr), axis=-1)

# Function for HSI to RGB conversion
def hsi_to_rgb(hsi_image):
    h, s, i = hsi_image[:,:,0], hsi_image[:,:,1], hsi_image[:,:,2]

    # Convert Hue from [0, 360] to [0, 2pi]
    h = np.radians(h)

    # Compute RGB components
    r = np.zeros_like(h)
    g = np.zeros_like(h)
    b = np.zeros_like(h)

    # For H in [0, 2pi]
    for k in range(h.shape[0]):
        for l in range(h.shape[1]):
            if s[k, l] == 0:  # Achromatic case (gray)
                r[k, l] = i[k, l]
                g[k, l] = i[k, l]
                b[k, l] = i[k, l]
            else:
                if 0 <= h[k, l] < 2 * np.pi / 3:
                    b[k, l] = i[k, l] * (1 - s[k, l])
                    r[k, l] = i[k, l] * (1 + s[k, l] * np.cos(h[k, l]) / np.cos(np.pi / 3 - h[k, l]))
                    g[k, l] = 3 * i[k, l] - (r[k, l] + b[k, l])
                # Other hue ranges can be added similarly

    return np.stack((r, g, b), axis=-1)

# Function for YCbCr to RGB conversion
def ycbcr_to_rgb(ycbcr_image):
    y, cb, cr = ycbcr_image[:,:,0], ycbcr_image[:,:,1], ycbcr_image[:,:,2]

    r = y + 1.402 * (cr - 128)
    g = y - 0.344136 * (cb - 128) - 0.714136 * (cr - 128)
    b = y + 1.772 * (cb - 128)

    return np.stack((r, g, b), axis=-1)

# Load an example image (replace 'your_image.jpg' with your image file)
image = cv2.imread('/content/images (6).jpeg')

# Convert to RGB (OpenCV loads images in BGR by default)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Perform the color space conversions
hsi_image = rgb_to_hsi(image_rgb)
ycbcr_image = rgb_to_ycbcr(image_rgb)

# Convert back to RGB from HSI and YCbCr
image_rgb_from_hsi = hsi_to_rgb(hsi_image)
image_rgb_from_ycbcr = ycbcr_to_rgb(ycbcr_image)

# Display the results
plt.figure(figsize=(10, 10))

plt.subplot(2, 3, 1)
plt.imshow(image_rgb)
plt.title('Original RGB Image')

plt.subplot(2, 3, 2)
plt.imshow(hsi_image)
plt.title('HSI Image')

plt.subplot(2, 3, 3)
plt.imshow(ycbcr_image)
plt.title('YCbCr Image')

plt.subplot(2, 3, 4)
plt.imshow(image_rgb_from_hsi)
plt.title('RGB from HSI')

plt.subplot(2, 3, 5)
plt.imshow(image_rgb_from_ycbcr)
plt.title('RGB from YCbCr')

plt.show()

"""Perform color histogram equalization on a color image and analyze the results."""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

def histogram_equalization_color(image):
    # Convert the image from BGR to HSV color space
    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    # Split the HSV image into individual channels
    h, s, v = cv2.split(hsv_image)

    # Perform histogram equalization only on the Value channel (v)
    v_equalized = cv2.equalizeHist(v)

    # Merge the channels back
    hsv_equalized = cv2.merge([h, s, v_equalized])

    # Convert back to BGR color space
    image_equalized = cv2.cvtColor(hsv_equalized, cv2.COLOR_HSV2BGR)

    return image_equalized

def plot_histograms(image, image_equalized):
    # Convert the images from BGR to RGB for Matplotlib
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image_equalized_rgb = cv2.cvtColor(image_equalized, cv2.COLOR_BGR2RGB)

    # Plot histograms for the original and equalized images
    plt.figure(figsize=(12, 6))

    # Original Image Histogram
    plt.subplot(1, 2, 1)
    plt.title("Original Image Histogram")
    plt.hist(image_rgb.flatten(), bins=256, color='gray', alpha=0.6)
    plt.xlim([0, 256])

    # Equalized Image Histogram
    plt.subplot(1, 2, 2)
    plt.title("Equalized Image Histogram")
    plt.hist(image_equalized_rgb.flatten(), bins=256, color='gray', alpha=0.6)
    plt.xlim([0, 256])

    plt.show()

def main():
    # Load a color image (replace 'your_image_path_here.jpg' with the actual path)
    image = cv2.imread('/content/images (6).jpeg')

    # Perform color histogram equalization
    image_equalized = histogram_equalization_color(image)

    # Plot histograms for both images
    plot_histograms(image, image_equalized)

    # Display the original and equalized images using cv2_imshow
    cv2_imshow(image)  # Original Image
    cv2_imshow(image_equalized)  # Equalized Image

    # Add titles for the images
    print("Original Image (before equalization)")
    print("Equalized Image (after histogram equalization)")

if __name__ == "__main__":
    main()

"""Implement color edge detection using Sobel or Canny operators"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

def sobel_edge_detection(image):
    # Convert the image to grayscale
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply Sobel operator for edge detection
    sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)  # Sobel in X direction
    sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)  # Sobel in Y direction

    # Calculate the magnitude of the gradient
    sobel_edges = cv2.magnitude(sobel_x, sobel_y)

    # Convert back to uint8
    sobel_edges = np.uint8(np.absolute(sobel_edges))

    return sobel_edges

def canny_edge_detection(image):
    # Convert the image to grayscale
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply Canny edge detection
    canny_edges = cv2.Canny(gray_image, 100, 200)

    return canny_edges

def main():
    # Load a color image (replace 'your_image_path_here.jpg' with the actual path)
    image = cv2.imread('/content/images (6).jpeg')

    # Perform Sobel edge detection
    sobel_edges = sobel_edge_detection(image)

    # Perform Canny edge detection
    canny_edges = canny_edge_detection(image)

    # Display the original image, Sobel and Canny edge detection results using cv2_imshow
    print("Original Image")
    cv2_imshow(image)

    print("Sobel Edge Detection")
    cv2_imshow(sobel_edges)

    print("Canny Edge Detection")
    cv2_imshow(canny_edges)

if __name__ == "__main__":
    main()

"""Image Segmentation: Implement thresholding, region-based, and edge-based segmentation
techniques.
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Read the image
image = cv2.imread('/content/images (6).jpeg', cv2.IMREAD_COLOR)
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Thresholding Segmentation
def thresholding_segmentation(image):
    _, thresholded = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)
    return thresholded

# Region-based Segmentation (Using Watershed algorithm)
def region_based_segmentation(image):
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply Gaussian Blur to reduce noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Threshold the image
    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # Compute the distance transform
    dist_transform = cv2.distanceTransform(thresh, cv2.DIST_L2, 5)
    _, fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)

    # Subtract the foreground from the original image to find the background
    bg = cv2.dilate(thresh, None, iterations=3)

    # Ensure both fg and bg are of the same type (uint8)
    fg = np.uint8(fg)
    bg = np.uint8(bg)

    # Combine the foreground and background to find the markers
    markers = cv2.add(fg, bg)
    markers = cv2.convertScaleAbs(markers)

    # Perform watershed segmentation
    markers = cv2.watershed(image, markers)
    image[markers == -1] = [0, 0, 255]  # Mark boundaries in red
    return image

# Edge-based Segmentation (Using Canny Edge Detection)
def edge_based_segmentation(image):
    # Convert image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply GaussianBlur to reduce noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Perform Canny Edge Detection
    edges = cv2.Canny(blurred, 100, 200)

    return edges

# Apply Thresholding Segmentation
thresholded_image = thresholding_segmentation(gray_image)

# Apply Region-based Segmentation
region_based_image = region_based_segmentation(image.copy())

# Apply Edge-based Segmentation
edge_based_image = edge_based_segmentation(image)

# Plotting the results
plt.figure(figsize=(12, 8))

# Original Image
plt.subplot(2, 2, 1)
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title("Original Image")
plt.axis('off')

# Thresholding Segmentation
plt.subplot(2, 2, 2)
plt.imshow(thresholded_image, cmap='gray')
plt.title("Thresholding Segmentation")
plt.axis('off')

# Region-based Segmentation
plt.subplot(2, 2, 3)
plt.imshow(cv2.cvtColor(region_based_image, cv2.COLOR_BGR2RGB))
plt.title("Region-based Segmentation")
plt.axis('off')

# Edge-based Segmentation
plt.subplot(2, 2, 4)
plt.imshow(edge_based_image, cmap='gray')
plt.title("Edge-based Segmentation (Canny)")
plt.axis('off')

# Show the segmented images
plt.tight_layout()
plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Read the image
image = cv2.imread('/content/images (6).jpeg', cv2.IMREAD_COLOR)
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Thresholding Segmentation
def thresholding_segmentation(image):
    _, thresholded = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)
    return thresholded

# Region-based Segmentation (Using Watershed algorithm)
def region_based_segmentation(image):
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply Gaussian Blur to reduce noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Threshold the image
    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # Compute the distance transform
    dist_transform = cv2.distanceTransform(thresh, cv2.DIST_L2, 5)
    _, fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)

    # Subtract the foreground from the original image to find the background
    bg = cv2.dilate(thresh, None, iterations=3)

    # Ensure both fg and bg are of the same type (uint8)
    fg = np.uint8(fg)
    bg = np.uint8(bg)

    # Combine the foreground and background to find the markers
    markers = cv2.add(fg, bg)
    markers = cv2.convertScaleAbs(markers)

    # Convert markers to a 32-bit signed integer image (CV_32SC1)
    markers = np.int32(markers)

    # Perform watershed segmentation
    cv2.watershed(image, markers)

    # Mark boundaries (watershed boundary points will be marked as -1)
    image[markers == -1] = [0, 0, 255]  # Mark boundaries in red

    return image

# Edge-based Segmentation (Using Canny Edge Detection)
def edge_based_segmentation(image):
    # Convert image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply GaussianBlur to reduce noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Perform Canny Edge Detection
    edges = cv2.Canny(blurred, 100, 200)

    return edges

# Apply Thresholding Segmentation
thresholded_image = thresholding_segmentation(gray_image)

# Apply Region-based Segmentation
region_based_image = region_based_segmentation(image.copy())

# Apply Edge-based Segmentation
edge_based_image = edge_based_segmentation(image)

# Plotting the results
plt.figure(figsize=(12, 8))

# Original Image
plt.subplot(2, 2, 1)
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title("Original Image")
plt.axis('off')

# Thresholding Segmentation
plt.subplot(2, 2, 2)
plt.imshow(thresholded_image, cmap='gray')
plt.title("Thresholding Segmentation")
plt.axis('off')

# Region-based Segmentation
plt.subplot(2, 2, 3)
plt.imshow(cv2.cvtColor(region_based_image, cv2.COLOR_BGR2RGB))
plt.title("Region-based Segmentation")
plt.axis('off')

# Edge-based Segmentation
plt.subplot(2, 2, 4)
plt.imshow(edge_based_image, cmap='gray')
plt.title("Edge-based Segmentation (Canny)")
plt.axis('off')

# Show the segmented images
plt.tight_layout()
plt.show()

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

# Load the image
image = cv2.imread('/content/images (6).jpeg', cv2.IMREAD_GRAYSCALE)

# Check if the image is loaded successfully
if image is None:
    print("Error: Image not found.")
    exit()

# --- 1. Thresholding Segmentation ---
# Apply global thresholding
_, thresholded_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)

# Show thresholded image
cv2_imshow(thresholded_image)

# --- 2. Region-Based Segmentation ---
# Apply binary thresholding first to create a binary image
_, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)

# Find connected components (regions)
num_labels, labels = cv2.connectedComponents(binary_image)

# Convert labels to a displayable format (scaling them for visualization)
segmented_image = np.uint8(labels * 255 / num_labels)

# Show region-based segmentation result
cv2_imshow(segmented_image)

# --- 3. Edge-Based Segmentation ---
# Apply the Canny edge detection algorithm
edges = cv2.Canny(image, 100, 200)

# Show edge-based segmentation result
cv2_imshow(edges)

"""mage Morphological Processing: Perform erosion, dilation, opening, and closing operations
on binary images.
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

# Load the image in grayscale
image = cv2.imread('/content/images (6).jpeg', cv2.IMREAD_GRAYSCALE)

# Check if the image is loaded successfully
if image is None:
    print("Error: Image not found.")
    exit()

# Convert the image to a binary image using thresholding
_, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)

# --- 1. Erosion ---
# Erosion operation reduces the boundaries of the foreground object in the image
kernel = np.ones((5, 5), np.uint8)  # 5x5 kernel
eroded_image = cv2.erode(binary_image, kernel, iterations=1)

# Show the result of erosion
cv2_imshow(eroded_image)

# --- 2. Dilation ---
# Dilation operation increases the boundaries of the foreground object in the image
dilated_image = cv2.dilate(binary_image, kernel, iterations=1)

# Show the result of dilation
cv2_imshow(dilated_image)

# --- 3. Opening ---
# Opening operation is erosion followed by dilation, useful for removing small noise
opened_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)

# Show the result of opening
cv2_imshow(opened_image)

# --- 4. Closing ---
# Closing operation is dilation followed by erosion, useful for closing small holes inside the object
closed_image = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)

# Show the result of closing
cv2_imshow(closed_image)

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load a binary image
image = cv2.imread('/content/download-(6).png', cv2.IMREAD_GRAYSCALE)

# Create a kernel for morphological operations
kernel = np.ones((5, 5), np.uint8)

# Perform morphological operations
erosion = cv2.erode(image, kernel, iterations=1)
dilation = cv2.dilate(image, kernel, iterations=1)
opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)
closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)

# Display results
titles = ['Original Image', 'Erosion', 'Dilation', 'Opening', 'Closing']
images = [image, erosion, dilation, opening, closing]

plt.figure(figsize=(10, 8))
for i in range(5):
    plt.subplot(2, 3, i + 1)
    plt.imshow(images[i], cmap='gray')
    plt.title(titles[i])
    plt.axis('off')

plt.tight_layout()
plt.show()

"""Image Registration: Implement image registration techniques for aligning multiple images"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow  # For displaying images in Colab

# Load reference (fixed) and moving images in grayscale
ref_image = cv2.imread('/content/im1-copy.png', cv2.IMREAD_GRAYSCALE)
moving_image = cv2.imread('/content/im2-copy.png', cv2.IMREAD_GRAYSCALE)

# Check if images are loaded properly
if ref_image is None or moving_image is None:
    print("Error: Unable to load images.")
    exit()

# Step 1: Detect ORB keypoints and descriptors
orb = cv2.ORB_create()
keypoints1, descriptors1 = orb.detectAndCompute(ref_image, None)
keypoints2, descriptors2 = orb.detectAndCompute(moving_image, None)

# Step 2: Match features using BFMatcher with Hamming distance
bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
matches = bf.match(descriptors1, descriptors2)

# Sort matches by distance
matches = sorted(matches, key=lambda x: x.distance)

# Draw matches for visualization (optional)
matched_image = cv2.drawMatches(ref_image, keypoints1, moving_image, keypoints2, matches[:10], None, flags=2)
cv2_imshow(matched_image)  # Use cv2_imshow to display the matches

# Step 3: Extract matched keypoints
src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)

# Step 4: Estimate Homography matrix
homography_matrix, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)

# Step 5: Warp the moving image using the homography matrix
aligned_image = cv2.warpPerspective(moving_image, homography_matrix, (ref_image.shape[1], ref_image.shape[0]))

# Step 6: Display results
cv2_imshow(ref_image)  # Display reference image
cv2_imshow(aligned_image)  # Display aligned image

# Save the aligned image
cv2.imwrite('aligned_image.jpg', aligned_image)
print("Aligned image saved as 'aligned_image.jpg'")

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load the images
image1 = cv2.imread('/content/im1-copy.png', cv2.IMREAD_GRAYSCALE)
image2 = cv2.imread('/content/im2-copy.png', cv2.IMREAD_GRAYSCALE)

# Initialize SIFT detector
sift = cv2.SIFT_create()

# Detect keypoints and descriptors
kp1, des1 = sift.detectAndCompute(image1, None)
kp2, des2 = sift.detectAndCompute(image2, None)

# Create a FLANN based matcher (Fast Library for Approximate Nearest Neighbors)
index_params = dict(algorithm=1, trees=10)
search_params = dict(checks=50)

flann = cv2.FlannBasedMatcher(index_params, search_params)

# Perform knn matching
matches = flann.knnMatch(des1, des2, k=2)

# Apply ratio test (Lowe's ratio test)
good_matches = []
for m, n in matches:
    if m.distance < 0.7 * n.distance:
        good_matches.append(m)

# Draw the matches
img_matches = cv2.drawMatches(image1, kp1, image2, kp2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

# Display the matching results
plt.figure(figsize=(10, 5))
plt.imshow(img_matches)
plt.title('Feature Matching')
plt.show()

# Extract location of good matches
points1 = np.zeros((len(good_matches), 2), dtype=np.float32)
points2 = np.zeros((len(good_matches), 2), dtype=np.float32)

for i, match in enumerate(good_matches):
    points1[i] = kp1[match.queryIdx].pt
    points2[i] = kp2[match.trainIdx].pt

# Compute homography (transformation matrix)
H, mask = cv2.findHomography(points1, points2, cv2.RANSAC, 5.0)

# Warp image2 to align with image1
height, width = image1.shape
im2_aligned = cv2.warpPerspective(image2, H, (width, height))

# Show the result
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(image1, cmap='gray')
plt.title('Image 1')

plt.subplot(1, 2, 2)
plt.imshow(im2_aligned, cmap='gray')
plt.title('Aligned Image 2')

plt.show()