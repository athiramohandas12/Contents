
"""Implement the 2D Discrete Fourier Transform (DFT) and its inverse"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.exposure import match_histograms

# Load a grayscale image
def load_grayscale_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Image not found or unable to read.")
    return image

# Contrast Enhancement using CLAHE and Gamma Correction
def contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2):
    # 1. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    enhanced_image = clahe.apply(image)

    # 2. Apply Gamma Correction
    gamma_corrected = np.power(enhanced_image / 255.0, gamma) * 255
    gamma_corrected = np.clip(gamma_corrected, 0, 255).astype(np.uint8)

    return gamma_corrected

# Evaluate contrast enhancement using CNR (Contrast-to-Noise Ratio)
def compute_cnr(original, enhanced):
    original_mean = np.mean(original)
    enhanced_mean = np.mean(enhanced)

    original_std = np.std(original)
    enhanced_std = np.std(enhanced)

    cnr_original = original_mean / original_std if original_std != 0 else 0
    cnr_enhanced = enhanced_mean / enhanced_std if enhanced_std != 0 else 0

    return cnr_original, cnr_enhanced

# Perform 2D Discrete Fourier Transform
def perform_dft(image):
    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)
    magnitude_spectrum = 20 * np.log(np.abs(dft_shifted) + 1)  # Logarithmic scale for visualization
    return dft, dft_shifted, magnitude_spectrum

# Perform Inverse 2D Discrete Fourier Transform
def perform_idft(dft_shifted):
    idft_shifted = np.fft.ifftshift(dft_shifted)
    reconstructed_image = np.fft.ifft2(idft_shifted)
    reconstructed_image = np.abs(reconstructed_image)
    return reconstructed_image

# Main script to test the contrast enhancement and DFT
def main():
    image_path = "/content/einstein.jpg"  # Replace with your image path
    image = load_grayscale_image(image_path)

    # Apply Contrast Enhancement
    enhanced_image = contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2)

    # Evaluate Effectiveness
    cnr_original, cnr_enhanced = compute_cnr(image, enhanced_image)

    print(f"CNR (Original): {cnr_original:.4f}")
    print(f"CNR (Enhanced): {cnr_enhanced:.4f}")

    # Perform 2D DFT
    dft, dft_shifted, magnitude_spectrum = perform_dft(image)

    # Perform Inverse DFT
    reconstructed_image = perform_idft(dft_shifted)

    # Plot results
    plt.figure(figsize=(15, 10))

    # Original Image
    plt.subplot(2, 2, 1)
    plt.title("Original Image")
    plt.imshow(image, cmap='gray')
    plt.axis('off')

    # Enhanced Image
    plt.subplot(2, 2, 2)
    plt.title("Enhanced Image")
    plt.imshow(enhanced_image, cmap='gray')
    plt.axis('off')

    # DFT Magnitude Spectrum
    plt.subplot(2, 2, 3)
    plt.title("DFT Magnitude Spectrum")
    plt.imshow(magnitude_spectrum, cmap='gray')
    plt.axis('off')

    # Reconstructed Image
    plt.subplot(2, 2, 4)
    plt.title("Reconstructed Image (Inverse DFT)")
    plt.imshow(reconstructed_image, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

"""Design low-pass, high-pass, and band-pass filters in the frequency domain. Apply them to an
image and analyze the results
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.exposure import match_histograms

# Load a grayscale image
def load_grayscale_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Image not found or unable to read.")
    return image

# Contrast Enhancement using CLAHE and Gamma Correction
def contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2):
    # 1. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    enhanced_image = clahe.apply(image)

    # 2. Apply Gamma Correction
    gamma_corrected = np.power(enhanced_image / 255.0, gamma) * 255
    gamma_corrected = np.clip(gamma_corrected, 0, 255).astype(np.uint8)

    return gamma_corrected

# Evaluate contrast enhancement using CNR (Contrast-to-Noise Ratio)
def compute_cnr(original, enhanced):
    original_mean = np.mean(original)
    enhanced_mean = np.mean(enhanced)

    original_std = np.std(original)
    enhanced_std = np.std(enhanced)

    cnr_original = original_mean / original_std if original_std != 0 else 0
    cnr_enhanced = enhanced_mean / enhanced_std if enhanced_std != 0 else 0

    return cnr_original, cnr_enhanced

# Perform 2D Discrete Fourier Transform
def perform_dft(image):
    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)
    magnitude_spectrum = 20 * np.log(np.abs(dft_shifted) + 1)  # Logarithmic scale for visualization
    return dft, dft_shifted, magnitude_spectrum

# Perform Inverse 2D Discrete Fourier Transform
def perform_idft(dft_shifted):
    idft_shifted = np.fft.ifftshift(dft_shifted)
    reconstructed_image = np.fft.ifft2(idft_shifted)
    reconstructed_image = np.abs(reconstructed_image)
    return reconstructed_image

# Design and apply frequency domain filters
def apply_frequency_filters(image):
    rows, cols = image.shape
    crow, ccol = rows // 2, cols // 2

    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)

    # Low-pass filter
    low_pass = np.zeros((rows, cols), np.uint8)
    low_pass[crow-30:crow+30, ccol-30:ccol+30] = 1
    dft_low_pass = dft_shifted * low_pass
    low_pass_image = perform_idft(dft_low_pass)

    # High-pass filter
    high_pass = np.ones((rows, cols), np.uint8)
    high_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_high_pass = dft_shifted * high_pass
    high_pass_image = perform_idft(dft_high_pass)

    # Band-pass filter
    band_pass = np.zeros((rows, cols), np.uint8)
    band_pass[crow-50:crow+50, ccol-50:ccol+50] = 1
    band_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_band_pass = dft_shifted * band_pass
    band_pass_image = perform_idft(dft_band_pass)

    return low_pass_image, high_pass_image, band_pass_image

# Main script to test the contrast enhancement and DFT
def main():
    image_path = "/content/einstein.jpg"  # Replace with your image path
    image = load_grayscale_image(image_path)

    # Apply Contrast Enhancement
    enhanced_image = contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2)

    # Evaluate Effectiveness
    cnr_original, cnr_enhanced = compute_cnr(image, enhanced_image)

    print(f"CNR (Original): {cnr_original:.4f}")
    print(f"CNR (Enhanced): {cnr_enhanced:.4f}")

    # Perform 2D DFT
    dft, dft_shifted, magnitude_spectrum = perform_dft(image)

    # Perform Inverse DFT
    reconstructed_image = perform_idft(dft_shifted)

    # Apply frequency domain filters
    low_pass_image, high_pass_image, band_pass_image = apply_frequency_filters(image)

    # Plot results
    plt.figure(figsize=(15, 10))

    # Original Image
    plt.subplot(2, 3, 1)
    plt.title("Original Image")
    plt.imshow(image, cmap='gray')
    plt.axis('off')

    # DFT Magnitude Spectrum
    plt.subplot(2, 3, 2)
    plt.title("DFT Magnitude Spectrum")
    plt.imshow(magnitude_spectrum, cmap='gray')
    plt.axis('off')

    # Reconstructed Image
    plt.subplot(2, 3, 3)
    plt.title("Reconstructed Image (Inverse DFT)")
    plt.imshow(reconstructed_image, cmap='gray')
    plt.axis('off')

    # Low-pass Filtered Image
    plt.subplot(2, 3, 4)
    plt.title("Low-pass Filter")
    plt.imshow(low_pass_image, cmap='gray')
    plt.axis('off')

    # High-pass Filtered Image
    plt.subplot(2, 3, 5)
    plt.title("High-pass Filter")
    plt.imshow(high_pass_image, cmap='gray')
    plt.axis('off')

    # Band-pass Filtered Image
    plt.subplot(2, 3, 6)
    plt.title("Band-pass Filter")
    plt.imshow(band_pass_image, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.exposure import match_histograms

# Load a grayscale image
def load_grayscale_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Image not found or unable to read.")
    return image

# Contrast Enhancement using CLAHE and Gamma Correction
def contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2):
    # 1. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    enhanced_image = clahe.apply(image)

    # 2. Apply Gamma Correction
    gamma_corrected = np.power(enhanced_image / 255.0, gamma) * 255
    gamma_corrected = np.clip(gamma_corrected, 0, 255).astype(np.uint8)

    return gamma_corrected

# Evaluate contrast enhancement using CNR (Contrast-to-Noise Ratio)
def compute_cnr(original, enhanced):
    original_mean = np.mean(original)
    enhanced_mean = np.mean(enhanced)

    original_std = np.std(original)
    enhanced_std = np.std(enhanced)

    cnr_original = original_mean / original_std if original_std != 0 else 0
    cnr_enhanced = enhanced_mean / enhanced_std if enhanced_std != 0 else 0

    return cnr_original, cnr_enhanced

# Perform 2D Discrete Fourier Transform
def perform_dft(image):
    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)
    magnitude_spectrum = 20 * np.log(np.abs(dft_shifted) + 1)  # Logarithmic scale for visualization
    return dft, dft_shifted, magnitude_spectrum

# Perform Inverse 2D Discrete Fourier Transform
def perform_idft(dft_shifted):
    idft_shifted = np.fft.ifftshift(dft_shifted)
    reconstructed_image = np.fft.ifft2(idft_shifted)
    reconstructed_image = np.abs(reconstructed_image)
    return reconstructed_image

# Design and apply frequency domain filters
def apply_frequency_filters(image):
    rows, cols = image.shape
    crow, ccol = rows // 2, cols // 2

    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)

    # Low-pass filter
    low_pass = np.zeros((rows, cols), np.uint8)
    low_pass[crow-30:crow+30, ccol-30:ccol+30] = 1
    dft_low_pass = dft_shifted * low_pass
    low_pass_image = perform_idft(dft_low_pass)

    # High-pass filter
    high_pass = np.ones((rows, cols), np.uint8)
    high_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_high_pass = dft_shifted * high_pass
    high_pass_image = perform_idft(dft_high_pass)

    # Band-pass filter
    band_pass = np.zeros((rows, cols), np.uint8)
    band_pass[crow-50:crow+50, ccol-50:ccol+50] = 1
    band_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_band_pass = dft_shifted * band_pass
    band_pass_image = perform_idft(dft_band_pass)

    return low_pass_image, high_pass_image, band_pass_image

# Main script to test the contrast enhancement and DFT
def main():
    image_path = "/content/MainAfter.jpg"  # Replace with your image path
    image = load_grayscale_image(image_path)

    # Apply Contrast Enhancement
    enhanced_image = contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2)

    # Evaluate Effectiveness
    cnr_original, cnr_enhanced = compute_cnr(image, enhanced_image)

    print(f"CNR (Original): {cnr_original:.4f}")
    print(f"CNR (Enhanced): {cnr_enhanced:.4f}")

    # Perform 2D DFT
    dft, dft_shifted, magnitude_spectrum = perform_dft(image)

    # Perform Inverse DFT
    reconstructed_image = perform_idft(dft_shifted)

    # Apply frequency domain filters
    low_pass_image, high_pass_image, band_pass_image = apply_frequency_filters(image)

    # Plot results
    plt.figure(figsize=(15, 10))

    # Original Image
    plt.subplot(2, 3, 1)
    plt.title("Original Image")
    plt.imshow(image, cmap='gray')
    plt.axis('off')

    # DFT Magnitude Spectrum
    plt.subplot(2, 3, 2)
    plt.title("DFT Magnitude Spectrum")
    plt.imshow(magnitude_spectrum, cmap='gray')
    plt.axis('off')

    # Reconstructed Image
    plt.subplot(2, 3, 3)
    plt.title("Reconstructed Image (Inverse DFT)")
    plt.imshow(reconstructed_image, cmap='gray')
    plt.axis('off')

    # Low-pass Filtered Image
    plt.subplot(2, 3, 4)
    plt.title("Low-pass Filter")
    plt.imshow(low_pass_image, cmap='gray')
    plt.axis('off')

    # High-pass Filtered Image
    plt.subplot(2, 3, 5)
    plt.title("High-pass Filter")
    plt.imshow(high_pass_image, cmap='gray')
    plt.axis('off')

    # Band-pass Filtered Image
    plt.subplot(2, 3, 6)
    plt.title("Band-pass Filter")
    plt.imshow(band_pass_image, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

"""Implement homomorphic filtering and apply it to an image with uneven illumination."""

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Step 1: Read the image
image = cv2.imread('/content/56368408-58561980-61c5-11e9-9800-0678dc02b4e7.png', cv2.IMREAD_GRAYSCALE)

# Step 2: Log Transformation
log_image = np.log1p(np.float32(image))

# Step 3: Fourier Transform
dft = cv2.dft(log_image, flags=cv2.DFT_COMPLEX_OUTPUT)
dft_shift = np.fft.fftshift(dft)

# Step 4: Create High-Pass Filter
rows, cols = image.shape
crow, ccol = rows // 2, cols // 2

# Create a circular high-pass filter
radius = 30  # Adjust the radius as needed
mask = np.ones((rows, cols, 2), np.float32)
cv2.circle(mask, (ccol, crow), radius, (0, 0, 0), -1)

# Step 5: Apply the filter
filtered_dft = dft_shift * mask

# Step 6: Inverse Fourier Transform
dft_ishift = np.fft.ifftshift(filtered_dft)
img_back = cv2.idft(dft_ishift)
img_back = cv2.magnitude(img_back[:, :, 0], img_back[:, :, 1])

# Step 7: Exponential Transformation
result_image = np.expm1(img_back)

# Step 8: Normalize the Resulting Image
result_image = np.uint8(cv2.normalize(result_image, None, 0, 255, cv2.NORM_MINMAX))

# Step 9: Display the results
plt.figure(figsize=(10, 5))
plt.subplot(1, 3, 1), plt.imshow(image, cmap='gray'), plt.title('Original Image')
plt.subplot(1, 3, 2), plt.imshow(log_image, cmap='gray'), plt.title('Log-Transformed Image')
plt.subplot(1, 3, 3), plt.imshow(result_image, cmap='gray'), plt.title('Homomorphic Filtered Image')
plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt

def homomorphic_filtering(image_path):
    # Load image
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    # Convert to float32
    img_float = np.float32(img)

    # Step 1: Logarithmic Transformation
    log_img = np.log1p(img_float)

    # Step 2: Fourier Transform
    f = np.fft.fft2(log_img)
    fshift = np.fft.fftshift(f)

    # Step 3: Create a high-pass filter
    rows, cols = img.shape
    crow, ccol = rows // 2, cols // 2
    mask = np.ones((rows, cols), dtype=np.float32)

    r = 30  # radius of the high-pass filter
    center = [crow, ccol]

    # Create a meshgrid of the frequency space
    x = np.fft.fftfreq(cols, 1 / cols)
    y = np.fft.fftfreq(rows, 1 / rows)
    X, Y = np.meshgrid(x, y)

    # Compute the distance from the center of the frequency domain
    distance = np.sqrt((X - center[0])**2 + (Y - center[1])**2)

    # Set mask to 0 where the distance is less than the radius (low-pass region)
    mask[distance < r] = 0

    # Step 4: Apply the high-pass filter to the frequency domain
    fshift_filtered = fshift * mask

    # Step 5: Inverse Fourier Transform to get back to spatial domain
    f_ishift = np.fft.ifftshift(fshift_filtered)
    img_back = np.fft.ifft2(f_ishift)
    img_back = np.real(img_back)

    # Step 6: Exponentiation to undo log transformation
    img_back = np.expm1(img_back)

    # Normalize to the range [0, 255]
    img_back = np.uint8(np.clip(img_back, 0, 255))

    # Display the results
    plt.figure(figsize=(10, 10))

    # Original image
    plt.subplot(1, 2, 1)
    plt.imshow(img, cmap='gray')
    plt.title('Original Image')
    plt.axis('off')

    # Homomorphic filtering result
    plt.subplot(1, 2, 2)
    plt.imshow(img_back, cmap='gray')
    plt.title('Homomorphic Filtered Image')
    plt.axis('off')

    plt.show()

# Apply homomorphic filtering to an image with uneven illumination
image_path = '/content/MainAfter.jpg'  # Replace with your image path
homomorphic_filtering(image_path)

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.exposure import match_histograms

# Load a grayscale image
def load_grayscale_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Image not found or unable to read.")
    return image

# Contrast Enhancement using CLAHE and Gamma Correction
def contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2):
    # 1. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    enhanced_image = clahe.apply(image)

    # 2. Apply Gamma Correction
    gamma_corrected = np.power(enhanced_image / 255.0, gamma) * 255
    gamma_corrected = np.clip(gamma_corrected, 0, 255).astype(np.uint8)

    return gamma_corrected

# Evaluate contrast enhancement using CNR (Contrast-to-Noise Ratio)
def compute_cnr(original, enhanced):
    original_mean = np.mean(original)
    enhanced_mean = np.mean(enhanced)

    original_std = np.std(original)
    enhanced_std = np.std(enhanced)

    cnr_original = original_mean / original_std if original_std != 0 else 0
    cnr_enhanced = enhanced_mean / enhanced_std if enhanced_std != 0 else 0

    return cnr_original, cnr_enhanced

# Perform 2D Discrete Fourier Transform
def perform_dft(image):
    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)
    magnitude_spectrum = 20 * np.log(np.abs(dft_shifted) + 1)  # Logarithmic scale for visualization
    return dft, dft_shifted, magnitude_spectrum

# Perform Inverse 2D Discrete Fourier Transform
def perform_idft(dft_shifted):
    idft_shifted = np.fft.ifftshift(dft_shifted)
    reconstructed_image = np.fft.ifft2(idft_shifted)
    reconstructed_image = np.abs(reconstructed_image)
    return reconstructed_image

# Design and apply frequency domain filters
def apply_frequency_filters(image):
    rows, cols = image.shape
    crow, ccol = rows // 2, cols // 2

    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)

    # Low-pass filter
    low_pass = np.zeros((rows, cols), np.uint8)
    low_pass[crow-30:crow+30, ccol-30:ccol+30] = 1
    dft_low_pass = dft_shifted * low_pass
    low_pass_image = perform_idft(dft_low_pass)

    # High-pass filter
    high_pass = np.ones((rows, cols), np.uint8)
    high_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_high_pass = dft_shifted * high_pass
    high_pass_image = perform_idft(dft_high_pass)

    # Band-pass filter
    band_pass = np.zeros((rows, cols), np.uint8)
    band_pass[crow-50:crow+50, ccol-50:ccol+50] = 1
    band_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_band_pass = dft_shifted * band_pass
    band_pass_image = perform_idft(dft_band_pass)

    return low_pass_image, high_pass_image, band_pass_image

# Perform Homomorphic Filtering
def homomorphic_filtering(image, gamma_low=0.5, gamma_high=2.0, cutoff=30):
    rows, cols = image.shape
    crow, ccol = rows // 2, cols // 2

    # Convert to log domain
    log_image = np.log1p(np.array(image, dtype=np.float64))

    # Apply DFT
    dft = np.fft.fft2(log_image)
    dft_shifted = np.fft.fftshift(dft)

    # Create Gaussian high-pass filter
    x, y = np.meshgrid(np.linspace(-ccol, ccol, cols), np.linspace(-crow, crow, rows))
    radius = np.sqrt(x**2 + y**2)
    filter_mask = 1 - np.exp(-(radius**2) / (2 * (cutoff**2)))

    # Apply filter
    dft_filtered = dft_shifted * ((gamma_high - gamma_low) * filter_mask + gamma_low)

    # Inverse DFT
    idft_shifted = np.fft.ifftshift(dft_filtered)
    filtered_image = np.fft.ifft2(idft_shifted)
    filtered_image = np.exp(np.abs(filtered_image)) - 1

    # Normalize to 8-bit range
    filtered_image = np.clip(filtered_image, 0, 255)
    filtered_image = filtered_image.astype(np.uint8)

    return filtered_image

# Main script to test the contrast enhancement, DFT, and homomorphic filtering
def main():
    image_path = "/content/MainAfter.jpg"  # Replace with your image path
    image = load_grayscale_image(image_path)

    # Apply Contrast Enhancement
    enhanced_image = contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2)

    # Evaluate Effectiveness
    cnr_original, cnr_enhanced = compute_cnr(image, enhanced_image)

    print(f"CNR (Original): {cnr_original:.4f}")
    print(f"CNR (Enhanced): {cnr_enhanced:.4f}")

    # Perform 2D DFT
    dft, dft_shifted, magnitude_spectrum = perform_dft(image)

    # Perform Inverse DFT
    reconstructed_image = perform_idft(dft_shifted)

    # Apply frequency domain filters
    low_pass_image, high_pass_image, band_pass_image = apply_frequency_filters(image)

    # Apply Homomorphic Filtering
    homomorphic_image = homomorphic_filtering(image)

    # Plot results
    plt.figure(figsize=(15, 12))

    # Original Image
    plt.subplot(2, 4, 1)
    plt.title("Original Image")
    plt.imshow(image, cmap='gray')
    plt.axis('off')

    # DFT Magnitude Spectrum
    plt.subplot(2, 4, 2)
    plt.title("DFT Magnitude Spectrum")
    plt.imshow(magnitude_spectrum, cmap='gray')
    plt.axis('off')

    # Reconstructed Image
    plt.subplot(2, 4, 3)
    plt.title("Reconstructed Image (Inverse DFT)")
    plt.imshow(reconstructed_image, cmap='gray')
    plt.axis('off')

    # Low-pass Filtered Image
    plt.subplot(2, 4, 4)
    plt.title("Low-pass Filter")
    plt.imshow(low_pass_image, cmap='gray')
    plt.axis('off')

    # High-pass Filtered Image
    plt.subplot(2, 4, 5)
    plt.title("High-pass Filter")
    plt.imshow(high_pass_image, cmap='gray')
    plt.axis('off')

    # Band-pass Filtered Image
    plt.subplot(2, 4, 6)
    plt.title("Band-pass Filter")
    plt.imshow(band_pass_image, cmap='gray')
    plt.axis('off')

    # Homomorphic Filtered Image
    plt.subplot(2, 4, 7)
    plt.title("Homomorphic Filter")
    plt.imshow(homomorphic_image, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage.exposure import match_histograms

# Load a grayscale image
def load_grayscale_image(image_path):
    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    if image is None:
        raise ValueError("Image not found or unable to read.")
    return image

# Contrast Enhancement using CLAHE and Gamma Correction
def contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2):
    # 1. Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)
    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)
    enhanced_image = clahe.apply(image)

    # 2. Apply Gamma Correction
    gamma_corrected = np.power(enhanced_image / 255.0, gamma) * 255
    gamma_corrected = np.clip(gamma_corrected, 0, 255).astype(np.uint8)

    return gamma_corrected

# Evaluate contrast enhancement using CNR (Contrast-to-Noise Ratio)
def compute_cnr(original, enhanced):
    original_mean = np.mean(original)
    enhanced_mean = np.mean(enhanced)

    original_std = np.std(original)
    enhanced_std = np.std(enhanced)

    cnr_original = original_mean / original_std if original_std != 0 else 0
    cnr_enhanced = enhanced_mean / enhanced_std if enhanced_std != 0 else 0

    return cnr_original, cnr_enhanced

# Perform 2D Discrete Fourier Transform
def perform_dft(image):
    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)
    magnitude_spectrum = 20 * np.log(np.abs(dft_shifted) + 1)  # Logarithmic scale for visualization
    return dft, dft_shifted, magnitude_spectrum

# Perform Inverse 2D Discrete Fourier Transform
def perform_idft(dft_shifted):
    idft_shifted = np.fft.ifftshift(dft_shifted)
    reconstructed_image = np.fft.ifft2(idft_shifted)
    reconstructed_image = np.abs(reconstructed_image)
    return reconstructed_image

# Design and apply frequency domain filters
def apply_frequency_filters(image):
    rows, cols = image.shape
    crow, ccol = rows // 2, cols // 2

    dft = np.fft.fft2(image)
    dft_shifted = np.fft.fftshift(dft)

    # Low-pass filter
    low_pass = np.zeros((rows, cols), np.uint8)
    low_pass[crow-30:crow+30, ccol-30:ccol+30] = 1
    dft_low_pass = dft_shifted * low_pass
    low_pass_image = perform_idft(dft_low_pass)

    # High-pass filter
    high_pass = np.ones((rows, cols), np.uint8)
    high_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_high_pass = dft_shifted * high_pass
    high_pass_image = perform_idft(dft_high_pass)

    # Band-pass filter
    band_pass = np.zeros((rows, cols), np.uint8)
    band_pass[crow-50:crow+50, ccol-50:ccol+50] = 1
    band_pass[crow-30:crow+30, ccol-30:ccol+30] = 0
    dft_band_pass = dft_shifted * band_pass
    band_pass_image = perform_idft(dft_band_pass)

    return low_pass_image, high_pass_image, band_pass_image

# Perform Homomorphic Filtering
def homomorphic_filtering(image, gamma_low=0.5, gamma_high=2.0, cutoff=30):
    rows, cols = image.shape
    crow, ccol = rows // 2, cols // 2

    # Convert to log domain
    log_image = np.log1p(np.array(image, dtype=np.float64))

    # Apply DFT
    dft = np.fft.fft2(log_image)
    dft_shifted = np.fft.fftshift(dft)

    # Create Gaussian high-pass filter
    x, y = np.meshgrid(np.linspace(-ccol, ccol, cols), np.linspace(-crow, crow, rows))
    radius = np.sqrt(x**2 + y**2)
    filter_mask = 1 - np.exp(-(radius**2) / (2 * (cutoff**2)))

    # Apply filter
    dft_filtered = dft_shifted * ((gamma_high - gamma_low) * filter_mask + gamma_low)

    # Inverse DFT
    idft_shifted = np.fft.ifftshift(dft_filtered)
    filtered_image = np.fft.ifft2(idft_shifted)
    filtered_image = np.exp(np.abs(filtered_image)) - 1

    # Normalize to 8-bit range
    filtered_image = np.clip(filtered_image, 0, 255)
    filtered_image = filtered_image.astype(np.uint8)

    return filtered_image

# Main script to test the contrast enhancement, DFT, and homomorphic filtering
def main():
    image_path = "/content/56368408-58561980-61c5-11e9-9800-0678dc02b4e7.png"  # Replace with your image path
    image = load_grayscale_image(image_path)

    # Apply Contrast Enhancement
    enhanced_image = contrast_enhancement(image, clip_limit=2.0, tile_grid_size=(8, 8), gamma=1.2)

    # Evaluate Effectiveness
    cnr_original, cnr_enhanced = compute_cnr(image, enhanced_image)

    print(f"CNR (Original): {cnr_original:.4f}")
    print(f"CNR (Enhanced): {cnr_enhanced:.4f}")

    # Perform 2D DFT
    dft, dft_shifted, magnitude_spectrum = perform_dft(image)

    # Perform Inverse DFT
    reconstructed_image = perform_idft(dft_shifted)

    # Apply frequency domain filters
    low_pass_image, high_pass_image, band_pass_image = apply_frequency_filters(image)

    # Apply Homomorphic Filtering
    homomorphic_image = homomorphic_filtering(image)

    # Plot results
    plt.figure(figsize=(15, 12))

    # Original Image
    plt.subplot(2, 4, 1)
    plt.title("Original Image")
    plt.imshow(image, cmap='gray')
    plt.axis('off')

    # DFT Magnitude Spectrum
    plt.subplot(2, 4, 2)
    plt.title("DFT Magnitude Spectrum")
    plt.imshow(magnitude_spectrum, cmap='gray')
    plt.axis('off')

    # Reconstructed Image
    plt.subplot(2, 4, 3)
    plt.title("Reconstructed Image (Inverse DFT)")
    plt.imshow(reconstructed_image, cmap='gray')
    plt.axis('off')

    # Low-pass Filtered Image
    plt.subplot(2, 4, 4)
    plt.title("Low-pass Filter")
    plt.imshow(low_pass_image, cmap='gray')
    plt.axis('off')

    # High-pass Filtered Image
    plt.subplot(2, 4, 5)
    plt.title("High-pass Filter")
    plt.imshow(high_pass_image, cmap='gray')
    plt.axis('off')

    # Band-pass Filtered Image
    plt.subplot(2, 4, 6)
    plt.title("Band-pass Filter")
    plt.imshow(band_pass_image, cmap='gray')
    plt.axis('off')

    # Homomorphic Filtered Image
    plt.subplot(2, 4, 7)
    plt.title("Homomorphic Filter")
    plt.imshow(homomorphic_image, cmap='gray')
    plt.axis('off')

    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    main()

import cv2
import numpy as np
import matplotlib.pyplot as plt

def homomorphic_filtering(image_path):
    # Load image
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)

    # Convert to float32
    img_float = np.float32(img)

    # Step 1: Logarithmic Transformation
    log_img = np.log1p(img_float)

    # Step 2: Fourier Transform
    f = np.fft.fft2(log_img)
    fshift = np.fft.fftshift(f)

    # Step 3: Create a high-pass filter
    rows, cols = img.shape
    crow, ccol = rows // 2, cols // 2
    mask = np.ones((rows, cols), dtype=np.float32)

    r = 30  # radius of the high-pass filter
    center = [crow, ccol]

    # Create a meshgrid of the frequency space
    x = np.fft.fftfreq(cols, 1 / cols)
    y = np.fft.fftfreq(rows, 1 / rows)
    X, Y = np.meshgrid(x, y)

    # Compute the distance from the center of the frequency domain
    distance = np.sqrt((X - center[0])**2 + (Y - center[1])**2)

    # Set mask to 0 where the distance is less than the radius (low-pass region)
    mask[distance < r] = 0

    # Step 4: Apply the high-pass filter to the frequency domain
    fshift_filtered = fshift * mask

    # Step 5: Inverse Fourier Transform to get back to spatial domain
    f_ishift = np.fft.ifftshift(fshift_filtered)
    img_back = np.fft.ifft2(f_ishift)
    img_back = np.real(img_back)

    # Step 6: Exponentiation to undo log transformation
    img_back = np.expm1(img_back)

    # Normalize to the range [0, 255]
    img_back = np.uint8(np.clip(img_back, 0, 255))

    # Display the results
    plt.figure(figsize=(10, 10))

    # Original image
    plt.subplot(1, 2, 1)
    plt.imshow(img, cmap='gray')
    plt.title('Original Image')
    plt.axis('off')

    # Homomorphic filtering result
    plt.subplot(1, 2, 2)
    plt.imshow(img_back, cmap='gray')
    plt.title('Homomorphic Filtered Image')
    plt.axis('off')

    plt.show()

# Apply homomorphic filtering to an image with uneven illumination
image_path = 'your_image_path.jpg'  # Replace with your image path
homomorphic_filtering(image_path)

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load the image
image = cv2.imread('/content/56368408-58561980-61c5-11e9-9800-0678dc02b4e7.png', cv2.IMREAD_GRAYSCALE)

# Convert the image to float32 and normalize
image_float = np.float32(image) + 1.0

# Log transformation to separate illumination and reflectance
log_image = np.log(image_float)

# Apply Fourier Transform
f_image = np.fft.fft2(log_image)
fshift = np.fft.fftshift(f_image)

# Create a high-pass filter (Gaussian filter for low-frequency removal)
rows, cols = image.shape
crow, ccol = rows // 2, cols // 2
d0 = 30  # cutoff frequency
x = np.arange(0, cols)
y = np.arange(0, rows)
X, Y = np.meshgrid(x, y)
distance = np.sqrt((X - ccol) ** 2 + (Y - crow) ** 2)
hp_filter = np.exp(-(distance ** 2) / (2 * (d0 ** 2)))

# Apply the filter in the frequency domain
fshift_hp = fshift * hp_filter

# Inverse FFT to get back to the spatial domain
f_ishift = np.fft.ifftshift(fshift_hp)
image_hp = np.fft.ifft2(f_ishift)
image_hp = np.real(image_hp)

# Exponentiate to reverse the log transformation
image_result = np.exp(image_hp) - 1.0

# Normalize the image to be in range [0, 255]
image_result = np.uint8(np.clip(image_result, 0, 255))

# Display the original and filtered images
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(image, cmap='gray')
plt.title('Original Image')
plt.subplot(1, 2, 2)
plt.imshow(image_result, cmap='gray')
plt.title('Filtered Image')
plt.show()

import numpy as np
import cv2
import matplotlib.pyplot as plt

# Function for RGB to HSI conversion
def rgb_to_hsi(rgb_image):
    # Normalize RGB values to [0,1]
    rgb_image = rgb_image / 255.0
    r, g, b = rgb_image[:,:,0], rgb_image[:,:,1], rgb_image[:,:,2]

    # Compute the intensity component
    intensity = (r + g + b) / 3

    # Compute the saturation component
    min_rgb = np.minimum(r, np.minimum(g, b))
    saturation = 1 - (3 / (r + g + b + 1e-6)) * min_rgb

    # Compute the hue component
    numerator = 0.5 * ((r - g) + (r - b))
    denominator = np.sqrt((r - g)**2 + (r - b)*(g - b))
    theta = np.arccos(numerator / (denominator + 1e-6))

    hue = np.degrees(theta)

    # Adjust hue based on RGB components
    hue[b > g] = 360 - hue[b > g]

    return np.stack((hue, saturation, intensity), axis=-1)

# Function for RGB to YCbCr conversion
def rgb_to_ycbcr(rgb_image):
    # Normalize RGB values to [0, 255]
    rgb_image = np.float32(rgb_image)

    # YCbCr Conversion Formula
    y = 0.299 * rgb_image[:,:,0] + 0.587 * rgb_image[:,:,1] + 0.114 * rgb_image[:,:,2]
    cb = -0.168736 * rgb_image[:,:,0] - 0.331264 * rgb_image[:,:,1] + 0.5 * rgb_image[:,:,2] + 128
    cr = 0.5 * rgb_image[:,:,0] - 0.418688 * rgb_image[:,:,1] - 0.081312 * rgb_image[:,:,2] + 128

    return np.stack((y, cb, cr), axis=-1)

# Function for HSI to RGB conversion
def hsi_to_rgb(hsi_image):
    h, s, i = hsi_image[:,:,0], hsi_image[:,:,1], hsi_image[:,:,2]

    # Convert Hue from [0, 360] to [0, 2pi]
    h = np.radians(h)

    # Compute RGB components
    r = np.zeros_like(h)
    g = np.zeros_like(h)
    b = np.zeros_like(h)

    # For H in [0, 2pi]
    for k in range(h.shape[0]):
        for l in range(h.shape[1]):
            if s[k, l] == 0:  # Achromatic case (gray)
                r[k, l] = i[k, l]
                g[k, l] = i[k, l]
                b[k, l] = i[k, l]
            else:
                if 0 <= h[k, l] < 2 * np.pi / 3:
                    b[k, l] = i[k, l] * (1 - s[k, l])
                    r[k, l] = i[k, l] * (1 + s[k, l] * np.cos(h[k, l]) / np.cos(np.pi / 3 - h[k, l]))
                    g[k, l] = 3 * i[k, l] - (r[k, l] + b[k, l])
                # Other hue ranges can be added similarly

    return np.stack((r, g, b), axis=-1)

# Function for YCbCr to RGB conversion
def ycbcr_to_rgb(ycbcr_image):
    y, cb, cr = ycbcr_image[:,:,0], ycbcr_image[:,:,1], ycbcr_image[:,:,2]

    r = y + 1.402 * (cr - 128)
    g = y - 0.344136 * (cb - 128) - 0.714136 * (cr - 128)
    b = y + 1.772 * (cb - 128)

    return np.stack((r, g, b), axis=-1)

# Load an example image (replace 'your_image.jpg' with your image file)
image = cv2.imread('/content/images (6).jpeg')

# Convert to RGB (OpenCV loads images in BGR by default)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Perform the color space conversions
hsi_image = rgb_to_hsi(image_rgb)
ycbcr_image = rgb_to_ycbcr(image_rgb)

# Convert back to RGB from HSI and YCbCr
image_rgb_from_hsi = hsi_to_rgb(hsi_image)
image_rgb_from_ycbcr = ycbcr_to_rgb(ycbcr_image)

# Display the results
plt.figure(figsize=(10, 10))

plt.subplot(2, 3, 1)
plt.imshow(image_rgb)
plt.title('Original RGB Image')

plt.subplot(2, 3, 2)
plt.imshow(hsi_image)
plt.title('HSI Image')

plt.subplot(2, 3, 3)
plt.imshow(ycbcr_image)
plt.title('YCbCr Image')

plt.subplot(2, 3, 4)
plt.imshow(image_rgb_from_hsi)
plt.title('RGB from HSI')

plt.subplot(2, 3, 5)
plt.imshow(image_rgb_from_ycbcr)
plt.title('RGB from YCbCr')

plt.show()

"""Perform color histogram equalization on a color image and analyze the results."""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

def histogram_equalization_color(image):
    # Convert the image from BGR to HSV color space
    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    # Split the HSV image into individual channels
    h, s, v = cv2.split(hsv_image)

    # Perform histogram equalization only on the Value channel (v)
    v_equalized = cv2.equalizeHist(v)

    # Merge the channels back
    hsv_equalized = cv2.merge([h, s, v_equalized])

    # Convert back to BGR color space
    image_equalized = cv2.cvtColor(hsv_equalized, cv2.COLOR_HSV2BGR)

    return image_equalized

def plot_histograms(image, image_equalized):
    # Convert the images from BGR to RGB for Matplotlib
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image_equalized_rgb = cv2.cvtColor(image_equalized, cv2.COLOR_BGR2RGB)

    # Plot histograms for the original and equalized images
    plt.figure(figsize=(12, 6))

    # Original Image Histogram
    plt.subplot(1, 2, 1)
    plt.title("Original Image Histogram")
    plt.hist(image_rgb.flatten(), bins=256, color='gray', alpha=0.6)
    plt.xlim([0, 256])

    # Equalized Image Histogram
    plt.subplot(1, 2, 2)
    plt.title("Equalized Image Histogram")
    plt.hist(image_equalized_rgb.flatten(), bins=256, color='gray', alpha=0.6)
    plt.xlim([0, 256])

    plt.show()

def main():
    # Load a color image (replace 'your_image_path_here.jpg' with the actual path)
    image = cv2.imread('/content/images (6).jpeg')

    # Perform color histogram equalization
    image_equalized = histogram_equalization_color(image)

    # Plot histograms for both images
    plot_histograms(image, image_equalized)

    # Display the original and equalized images using cv2_imshow
    cv2_imshow(image)  # Original Image
    cv2_imshow(image_equalized)  # Equalized Image

    # Add titles for the images
    print("Original Image (before equalization)")
    print("Equalized Image (after histogram equalization)")

if __name__ == "__main__":
    main()

"""Implement color edge detection using Sobel or Canny operators"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

def sobel_edge_detection(image):
    # Convert the image to grayscale
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply Sobel operator for edge detection
    sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)  # Sobel in X direction
    sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)  # Sobel in Y direction

    # Calculate the magnitude of the gradient
    sobel_edges = cv2.magnitude(sobel_x, sobel_y)

    # Convert back to uint8
    sobel_edges = np.uint8(np.absolute(sobel_edges))

    return sobel_edges

def canny_edge_detection(image):
    # Convert the image to grayscale
    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply Canny edge detection
    canny_edges = cv2.Canny(gray_image, 100, 200)

    return canny_edges

def main():
    # Load a color image (replace 'your_image_path_here.jpg' with the actual path)
    image = cv2.imread('/content/images (6).jpeg')

    # Perform Sobel edge detection
    sobel_edges = sobel_edge_detection(image)

    # Perform Canny edge detection
    canny_edges = canny_edge_detection(image)

    # Display the original image, Sobel and Canny edge detection results using cv2_imshow
    print("Original Image")
    cv2_imshow(image)

    print("Sobel Edge Detection")
    cv2_imshow(sobel_edges)

    print("Canny Edge Detection")
    cv2_imshow(canny_edges)

if __name__ == "__main__":
    main()

"""Image Segmentation: Implement thresholding, region-based, and edge-based segmentation
techniques.
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Read the image
image = cv2.imread('/content/images (6).jpeg', cv2.IMREAD_COLOR)
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Thresholding Segmentation
def thresholding_segmentation(image):
    _, thresholded = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)
    return thresholded

# Region-based Segmentation (Using Watershed algorithm)
def region_based_segmentation(image):
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply Gaussian Blur to reduce noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Threshold the image
    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # Compute the distance transform
    dist_transform = cv2.distanceTransform(thresh, cv2.DIST_L2, 5)
    _, fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)

    # Subtract the foreground from the original image to find the background
    bg = cv2.dilate(thresh, None, iterations=3)

    # Ensure both fg and bg are of the same type (uint8)
    fg = np.uint8(fg)
    bg = np.uint8(bg)

    # Combine the foreground and background to find the markers
    markers = cv2.add(fg, bg)
    markers = cv2.convertScaleAbs(markers)

    # Perform watershed segmentation
    markers = cv2.watershed(image, markers)
    image[markers == -1] = [0, 0, 255]  # Mark boundaries in red
    return image

# Edge-based Segmentation (Using Canny Edge Detection)
def edge_based_segmentation(image):
    # Convert image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply GaussianBlur to reduce noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Perform Canny Edge Detection
    edges = cv2.Canny(blurred, 100, 200)

    return edges

# Apply Thresholding Segmentation
thresholded_image = thresholding_segmentation(gray_image)

# Apply Region-based Segmentation
region_based_image = region_based_segmentation(image.copy())

# Apply Edge-based Segmentation
edge_based_image = edge_based_segmentation(image)

# Plotting the results
plt.figure(figsize=(12, 8))

# Original Image
plt.subplot(2, 2, 1)
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title("Original Image")
plt.axis('off')

# Thresholding Segmentation
plt.subplot(2, 2, 2)
plt.imshow(thresholded_image, cmap='gray')
plt.title("Thresholding Segmentation")
plt.axis('off')

# Region-based Segmentation
plt.subplot(2, 2, 3)
plt.imshow(cv2.cvtColor(region_based_image, cv2.COLOR_BGR2RGB))
plt.title("Region-based Segmentation")
plt.axis('off')

# Edge-based Segmentation
plt.subplot(2, 2, 4)
plt.imshow(edge_based_image, cmap='gray')
plt.title("Edge-based Segmentation (Canny)")
plt.axis('off')

# Show the segmented images
plt.tight_layout()
plt.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Read the image
image = cv2.imread('/content/images (6).jpeg', cv2.IMREAD_COLOR)
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Thresholding Segmentation
def thresholding_segmentation(image):
    _, thresholded = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)
    return thresholded

# Region-based Segmentation (Using Watershed algorithm)
def region_based_segmentation(image):
    # Convert to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply Gaussian Blur to reduce noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Threshold the image
    _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # Compute the distance transform
    dist_transform = cv2.distanceTransform(thresh, cv2.DIST_L2, 5)
    _, fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)

    # Subtract the foreground from the original image to find the background
    bg = cv2.dilate(thresh, None, iterations=3)

    # Ensure both fg and bg are of the same type (uint8)
    fg = np.uint8(fg)
    bg = np.uint8(bg)

    # Combine the foreground and background to find the markers
    markers = cv2.add(fg, bg)
    markers = cv2.convertScaleAbs(markers)

    # Convert markers to a 32-bit signed integer image (CV_32SC1)
    markers = np.int32(markers)

    # Perform watershed segmentation
    cv2.watershed(image, markers)

    # Mark boundaries (watershed boundary points will be marked as -1)
    image[markers == -1] = [0, 0, 255]  # Mark boundaries in red

    return image

# Edge-based Segmentation (Using Canny Edge Detection)
def edge_based_segmentation(image):
    # Convert image to grayscale
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

    # Apply GaussianBlur to reduce noise
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Perform Canny Edge Detection
    edges = cv2.Canny(blurred, 100, 200)

    return edges

# Apply Thresholding Segmentation
thresholded_image = thresholding_segmentation(gray_image)

# Apply Region-based Segmentation
region_based_image = region_based_segmentation(image.copy())

# Apply Edge-based Segmentation
edge_based_image = edge_based_segmentation(image)

# Plotting the results
plt.figure(figsize=(12, 8))

# Original Image
plt.subplot(2, 2, 1)
plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
plt.title("Original Image")
plt.axis('off')

# Thresholding Segmentation
plt.subplot(2, 2, 2)
plt.imshow(thresholded_image, cmap='gray')
plt.title("Thresholding Segmentation")
plt.axis('off')

# Region-based Segmentation
plt.subplot(2, 2, 3)
plt.imshow(cv2.cvtColor(region_based_image, cv2.COLOR_BGR2RGB))
plt.title("Region-based Segmentation")
plt.axis('off')

# Edge-based Segmentation
plt.subplot(2, 2, 4)
plt.imshow(edge_based_image, cmap='gray')
plt.title("Edge-based Segmentation (Canny)")
plt.axis('off')

# Show the segmented images
plt.tight_layout()
plt.show()

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

# Load the image
image = cv2.imread('/content/images (6).jpeg', cv2.IMREAD_GRAYSCALE)

# Check if the image is loaded successfully
if image is None:
    print("Error: Image not found.")
    exit()

# --- 1. Thresholding Segmentation ---
# Apply global thresholding
_, thresholded_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)

# Show thresholded image
cv2_imshow(thresholded_image)

# --- 2. Region-Based Segmentation ---
# Apply binary thresholding first to create a binary image
_, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)

# Find connected components (regions)
num_labels, labels = cv2.connectedComponents(binary_image)

# Convert labels to a displayable format (scaling them for visualization)
segmented_image = np.uint8(labels * 255 / num_labels)

# Show region-based segmentation result
cv2_imshow(segmented_image)

# --- 3. Edge-Based Segmentation ---
# Apply the Canny edge detection algorithm
edges = cv2.Canny(image, 100, 200)

# Show edge-based segmentation result
cv2_imshow(edges)

"""mage Morphological Processing: Perform erosion, dilation, opening, and closing operations
on binary images.
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

# Load the image in grayscale
image = cv2.imread('/content/images (6).jpeg', cv2.IMREAD_GRAYSCALE)

# Check if the image is loaded successfully
if image is None:
    print("Error: Image not found.")
    exit()

# Convert the image to a binary image using thresholding
_, binary_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)

# --- 1. Erosion ---
# Erosion operation reduces the boundaries of the foreground object in the image
kernel = np.ones((5, 5), np.uint8)  # 5x5 kernel
eroded_image = cv2.erode(binary_image, kernel, iterations=1)

# Show the result of erosion
cv2_imshow(eroded_image)

# --- 2. Dilation ---
# Dilation operation increases the boundaries of the foreground object in the image
dilated_image = cv2.dilate(binary_image, kernel, iterations=1)

# Show the result of dilation
cv2_imshow(dilated_image)

# --- 3. Opening ---
# Opening operation is erosion followed by dilation, useful for removing small noise
opened_image = cv2.morphologyEx(binary_image, cv2.MORPH_OPEN, kernel)

# Show the result of opening
cv2_imshow(opened_image)

# --- 4. Closing ---
# Closing operation is dilation followed by erosion, useful for closing small holes inside the object
closed_image = cv2.morphologyEx(binary_image, cv2.MORPH_CLOSE, kernel)

# Show the result of closing
cv2_imshow(closed_image)

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load a binary image
image = cv2.imread('/content/download-(6).png', cv2.IMREAD_GRAYSCALE)

# Create a kernel for morphological operations
kernel = np.ones((5, 5), np.uint8)

# Perform morphological operations
erosion = cv2.erode(image, kernel, iterations=1)
dilation = cv2.dilate(image, kernel, iterations=1)
opening = cv2.morphologyEx(image, cv2.MORPH_OPEN, kernel)
closing = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)

# Display results
titles = ['Original Image', 'Erosion', 'Dilation', 'Opening', 'Closing']
images = [image, erosion, dilation, opening, closing]

plt.figure(figsize=(10, 8))
for i in range(5):
    plt.subplot(2, 3, i + 1)
    plt.imshow(images[i], cmap='gray')
    plt.title(titles[i])
    plt.axis('off')

plt.tight_layout()
plt.show()

"""Image Registration: Implement image registration techniques for aligning multiple images"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow  # For displaying images in Colab

# Load reference (fixed) and moving images in grayscale
ref_image = cv2.imread('/content/im1-copy.png', cv2.IMREAD_GRAYSCALE)
moving_image = cv2.imread('/content/im2-copy.png', cv2.IMREAD_GRAYSCALE)

# Check if images are loaded properly
if ref_image is None or moving_image is None:
    print("Error: Unable to load images.")
    exit()

# Step 1: Detect ORB keypoints and descriptors
orb = cv2.ORB_create()
keypoints1, descriptors1 = orb.detectAndCompute(ref_image, None)
keypoints2, descriptors2 = orb.detectAndCompute(moving_image, None)

# Step 2: Match features using BFMatcher with Hamming distance
bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
matches = bf.match(descriptors1, descriptors2)

# Sort matches by distance
matches = sorted(matches, key=lambda x: x.distance)

# Draw matches for visualization (optional)
matched_image = cv2.drawMatches(ref_image, keypoints1, moving_image, keypoints2, matches[:10], None, flags=2)
cv2_imshow(matched_image)  # Use cv2_imshow to display the matches

# Step 3: Extract matched keypoints
src_pts = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)
dst_pts = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)

# Step 4: Estimate Homography matrix
homography_matrix, mask = cv2.findHomography(dst_pts, src_pts, cv2.RANSAC, 5.0)

# Step 5: Warp the moving image using the homography matrix
aligned_image = cv2.warpPerspective(moving_image, homography_matrix, (ref_image.shape[1], ref_image.shape[0]))

# Step 6: Display results
cv2_imshow(ref_image)  # Display reference image
cv2_imshow(aligned_image)  # Display aligned image

# Save the aligned image
cv2.imwrite('aligned_image.jpg', aligned_image)
print("Aligned image saved as 'aligned_image.jpg'")

import cv2
import numpy as np
import matplotlib.pyplot as plt

# Load the images
image1 = cv2.imread('/content/im1-copy.png', cv2.IMREAD_GRAYSCALE)
image2 = cv2.imread('/content/im2-copy.png', cv2.IMREAD_GRAYSCALE)

# Initialize SIFT detector
sift = cv2.SIFT_create()

# Detect keypoints and descriptors
kp1, des1 = sift.detectAndCompute(image1, None)
kp2, des2 = sift.detectAndCompute(image2, None)

# Create a FLANN based matcher (Fast Library for Approximate Nearest Neighbors)
index_params = dict(algorithm=1, trees=10)
search_params = dict(checks=50)

flann = cv2.FlannBasedMatcher(index_params, search_params)

# Perform knn matching
matches = flann.knnMatch(des1, des2, k=2)

# Apply ratio test (Lowe's ratio test)
good_matches = []
for m, n in matches:
    if m.distance < 0.7 * n.distance:
        good_matches.append(m)

# Draw the matches
img_matches = cv2.drawMatches(image1, kp1, image2, kp2, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)

# Display the matching results
plt.figure(figsize=(10, 5))
plt.imshow(img_matches)
plt.title('Feature Matching')
plt.show()

# Extract location of good matches
points1 = np.zeros((len(good_matches), 2), dtype=np.float32)
points2 = np.zeros((len(good_matches), 2), dtype=np.float32)

for i, match in enumerate(good_matches):
    points1[i] = kp1[match.queryIdx].pt
    points2[i] = kp2[match.trainIdx].pt

# Compute homography (transformation matrix)
H, mask = cv2.findHomography(points1, points2, cv2.RANSAC, 5.0)

# Warp image2 to align with image1
height, width = image1.shape
im2_aligned = cv2.warpPerspective(image2, H, (width, height))

# Show the result
plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.imshow(image1, cmap='gray')
plt.title('Image 1')

plt.subplot(1, 2, 2)
plt.imshow(im2_aligned, cmap='gray')
plt.title('Aligned Image 2')

plt.show()